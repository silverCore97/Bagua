{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Horovod_new_alg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNu8g4qCEXDluHBhrc6o5LO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silverCore97/Bagua/blob/main/Horovod_new_alg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The implementation for **QSparseLocal-SGD** can be found under `horovod/tensorflow/__init__.py`. The parameters of the compression scheme are provided under `horovod/tensorflow/config.py`. The example Resnet training scripts, which also contains the local iteration logic, are in `train_resnet.py` and `eval_resnet.py`."
      ],
      "metadata": {
        "id": "DCYcQcRHeZfn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`horovod/tensorflow/config.py`"
      ],
      "metadata": {
        "id": "OPed6d6_jNpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sparsify = True \n",
        "use_memory = True\n",
        "quantization_scheme = 'qsgd' \n",
        "quantization_levels = 256\n",
        "top_k_sparsification = True\n",
        "k = 1000\n",
        "use_normalization = True"
      ],
      "metadata": {
        "id": "AdQ8y-ijjH4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`horovod/tensorflow/__init__.py`"
      ],
      "metadata": {
        "id": "NsvUFzrYiffj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "# Modifications copyright (C) 2017 Uber Technologies, Inc.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "# pylint: disable=g-short-docstring-punctuation\n",
        "\"\"\"## Communicating Between Processes with MPI\n",
        "TensorFlow natively provides inter-device communication through send and\n",
        "receive ops and inter-node communication through Distributed TensorFlow, based\n",
        "on the same send and receive abstractions. On HPC clusters where Infiniband or\n",
        "other high-speed node interconnects are available, these can end up being\n",
        "insufficient for synchronous data-parallel training (without asynchronous\n",
        "gradient descent). This module implements a variety of MPI ops which can take\n",
        "advantage of hardware-specific MPI libraries for efficient communication.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "from horovod.common import check_extension\n",
        "\n",
        "check_extension('horovod.tensorflow', 'HOROVOD_WITH_TENSORFLOW', __file__, 'mpi_lib')\n",
        "\n",
        "from horovod.tensorflow.compression import Compression\n",
        "from horovod.tensorflow.mpi_ops import allgather, broadcast, _allreduce\n",
        "from horovod.tensorflow.mpi_ops import init, shutdown\n",
        "from horovod.tensorflow.mpi_ops import size, local_size, rank, local_rank\n",
        "from horovod.tensorflow.mpi_ops import mpi_threads_supported\n",
        "from horovod.tensorflow.util import _executing_eagerly\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.python.ops import init_ops\n",
        "\n",
        "from horovod.tensorflow.config import *\n",
        "\n",
        "def qsgd_compk(eta_grad, memory, topK_flag, s):\n",
        "\n",
        "    def qsgd(var):\n",
        "        level_float = s*tf.abs(var) / norm1 \n",
        "        previous_level = tf.floor(level_float)\n",
        "        is_next_level = tf.less(tf.random_uniform(shape = tf.shape(var), dtype = tf.float32),(level_float - previous_level))\n",
        "        is_next_level = tf.cast(is_next_level,tf.float32)\n",
        "        new_level = previous_level + is_next_level\n",
        "        unnormalized = tf.sign(var) * new_level * norm1 / s\n",
        "        beta = tf.cast(tf.size(var), dtype=tf.float32)/tf.cast(s*s, dtype=tf.float32)\n",
        "        return unnormalized/(1.0+beta) if use_normalization else unnormalized \n",
        "\n",
        "    def signq(var):\n",
        "        one_norm = tf.norm(var, ord=1)\n",
        "        return one_norm*tf.sign(var+1e-13)/tf.cast(tf.size(var), dtype=tf.float32)\n",
        "    \n",
        "    def get_quantization(q):\n",
        "        if q == 'qsgd':\n",
        "            return qsgd\n",
        "        elif q == 'sign':\n",
        "            return signq\n",
        "        else:\n",
        "            return lambda x:x\n",
        "\n",
        "    if not sparsify:\n",
        "        norm1 = tf.norm(eta_grad) + tf.constant(1e-5, dtype=tf.float32)\n",
        "        if use_memory:\n",
        "            input = memory+eta_grad\n",
        "        else:\n",
        "            input = eta_grad\n",
        "\n",
        "        func = get_quantization(quantization_scheme)\n",
        "        q = func(input)\n",
        "\n",
        "        return q, input-q\n",
        "\n",
        "    input = memory + eta_grad\n",
        "    org_shape = tf.shape(input)\n",
        "    numel = tf.size(input)\n",
        "    K = tf.minimum(tf.constant(k, dtype=tf.int32), numel)\n",
        "\n",
        "    if topK_flag:\n",
        "        _, indices = tf.nn.top_k(tf.reshape(tf.abs(input),[-1]), k=K)\n",
        "    else:\n",
        "        indices = tf.py_func(np.random.choice, [tf.range(numel), K, tf.constant(False, dtype=tf.bool)], tf.int32)\n",
        "\n",
        "    flat_input = tf.reshape(input, [-1])\n",
        "    values = tf.gather(flat_input, indices) \n",
        "    norm1 = tf.norm(values)\n",
        "    quantization_func = get_quantization(quantization_scheme)\n",
        "    flattened_quantized = tf.convert_to_tensor(tf.IndexedSlices(quantization_func(values), indices, dense_shape=tf.expand_dims(numel, [-1])))\n",
        "    quantization = tf.reshape(flattened_quantized, shape=org_shape)\n",
        "\n",
        "    q_func = lambda: quantization\n",
        "    zero_tensor = lambda: tf.zeros(tf.shape(input),tf.float32)\n",
        "\n",
        "    q = tf.cond(tf.less(tf.constant(0, dtype=tf.float32), norm1), q_func, zero_tensor)\n",
        "\n",
        "    err = input - q\n",
        "    return q, err \n",
        "\n",
        "def allreduce(tensor, var, opt, wipe_memory, average=True, device_dense='', device_sparse='',\n",
        "              compression=Compression.none):\n",
        "    \"\"\"Perform an allreduce on a tf.Tensor or tf.IndexedSlices.\n",
        "    This function performs a bandwidth-optimal ring allreduce on the input\n",
        "    tensor. If the input is an tf.IndexedSlices, the function instead does an\n",
        "    allgather on the values and the indices, effectively doing an allreduce on\n",
        "    the represented tensor.\n",
        "    Arguments:\n",
        "        tensor: tf.Tensor, tf.Variable, or tf.IndexedSlices to reduce.\n",
        "                The shape of the input must be identical across all ranks.\n",
        "        average: If True, computes the average over all ranks.\n",
        "                 Otherwise, computes the sum over all ranks.\n",
        "        device_dense: Device to be used for dense tensors. Uses GPU by default\n",
        "                      if Horovod was built with HOROVOD_GPU_ALLREDUCE.\n",
        "        device_sparse: Device to be used for sparse tensors. Uses GPU by default\n",
        "                       if Horovod was built with HOROVOD_GPU_ALLGATHER.\n",
        "        compression: Compression algorithm used to reduce the amount of data\n",
        "                     sent and received by each worker node.  Defaults to not\n",
        "                     using compression.\n",
        "    Returns:\n",
        "        A tensor of the same shape and type as `tensor`, summed across all\n",
        "        processes.\n",
        "    \"\"\"\n",
        "    if isinstance(tensor, tf.IndexedSlices):\n",
        "        with tf.device(device_sparse):\n",
        "            # For IndexedSlices, do two allgathers instead of an allreduce.\n",
        "            horovod_size = tf.cast(size(), tensor.values.dtype)\n",
        "            values = allgather(tensor.values)\n",
        "            indices = allgather(tensor.indices)\n",
        "\n",
        "            # To make this operation into an average, divide allgathered values by\n",
        "            # the Horovod size.\n",
        "            new_values = tf.div(values, horovod_size) if average else values\n",
        "        return tf.IndexedSlices(new_values, indices,\n",
        "                                dense_shape=tensor.dense_shape)\n",
        "    else:\n",
        "        with tf.device(device_dense):\n",
        "            init = init_ops.constant_initializer(0, dtype=tensor.dtype)\n",
        "            memory = opt._get_or_make_slot_with_initializer(var, init, var.get_shape(), tensor.dtype, 'memory', 'error')\n",
        "\n",
        "            tensor_quantized, error = qsgd_compk(tensor, memory, topK_flag=top_k_sparsification, s=quantization_levels)\n",
        "\n",
        "            error_or_zero = tf.cond(wipe_memory, lambda: tf.zeros_like(error), lambda: error)\n",
        "            mem_update_op = memory.assign(error_or_zero)\n",
        "\n",
        "            with tf.control_dependencies([mem_update_op]):\n",
        "              horovod_size = tf.cast(size(), dtype=tensor.dtype)\n",
        "              tensor_compressed, ctx = compression.compress(tensor_quantized)\n",
        "              summed_tensor_compressed = _allreduce(tensor_compressed)\n",
        "              summed_tensor = compression.decompress(summed_tensor_compressed, ctx)\n",
        "              new_tensor = (tf.div(summed_tensor, horovod_size)\n",
        "                          if average else summed_tensor)\n",
        "\n",
        "        return new_tensor\n",
        "\n",
        "\n",
        "def broadcast_global_variables(root_rank):\n",
        "    \"\"\"Broadcasts all global variables from root rank to all other processes.\n",
        "    Arguments:\n",
        "        root_rank: rank of the process from which global variables will be broadcasted\n",
        "        to all other processes.\n",
        "    \"\"\"\n",
        "    return tf.group(*[tf.assign(var, broadcast(var, root_rank))\n",
        "                      for var in tf.global_variables()])\n",
        "\n",
        "\n",
        "class BroadcastGlobalVariablesHook(tf.train.SessionRunHook):\n",
        "    \"\"\"\n",
        "    SessionRunHook that will broadcast all global variables from root rank\n",
        "    to all other processes during initialization.\n",
        "    This is necessary to ensure consistent initialization of all workers when\n",
        "    training is started with random weights or restored from a checkpoint.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, root_rank, device=''):\n",
        "        \"\"\"Construct a new BroadcastGlobalVariablesHook that will broadcast all\n",
        "        global variables from root rank to all other processes during initialization.\n",
        "        Args:\n",
        "          root_rank:\n",
        "            Rank that will send data, other ranks will receive data.\n",
        "          device:\n",
        "            Device to be used for broadcasting. Uses GPU by default\n",
        "            if Horovod was build with HOROVOD_GPU_BROADCAST.\n",
        "        \"\"\"\n",
        "        super(BroadcastGlobalVariablesHook, self).__init__()\n",
        "        self.root_rank = root_rank\n",
        "        self.bcast_op = None\n",
        "        self.device = device\n",
        "\n",
        "    def begin(self):\n",
        "        if not self.bcast_op or self.bcast_op.graph != tf.get_default_graph():\n",
        "            with tf.device(self.device):\n",
        "                self.bcast_op = broadcast_global_variables(self.root_rank)\n",
        "\n",
        "    def after_create_session(self, session, coord):\n",
        "        session.run(self.bcast_op)\n",
        "\n",
        "\n",
        "class DistributedOptimizer(tf.train.Optimizer):\n",
        "    \"\"\"An optimizer that wraps another tf.Optimizer, using an allreduce to\n",
        "    average gradient values before applying gradients to model weights.\"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, name=None, use_locking=False, device_dense='',\n",
        "                 device_sparse='', compression=Compression.none,\n",
        "                 sparse_as_dense=False):\n",
        "        \"\"\"Construct a new DistributedOptimizer, which uses another optimizer\n",
        "        under the hood for computing single-process gradient values and\n",
        "        applying gradient updates after the gradient values have been averaged\n",
        "        across all the Horovod ranks.\n",
        "        Args:\n",
        "          optimizer:\n",
        "            Optimizer to use for computing gradients and applying updates.\n",
        "          name:\n",
        "            Optional name prefix for the operations created when applying\n",
        "            gradients. Defaults to \"Distributed\" followed by the provided\n",
        "            optimizer type.\n",
        "          use_locking:\n",
        "            Whether to use locking when updating variables.\n",
        "            See Optimizer.__init__ for more info.\n",
        "          device_dense:\n",
        "            Device to be used for dense tensors. Uses GPU by default\n",
        "            if Horovod was build with HOROVOD_GPU_ALLREDUCE.\n",
        "          device_sparse:\n",
        "            Device to be used for sparse tensors. Uses GPU by default\n",
        "            if Horovod was build with HOROVOD_GPU_ALLGATHER.\n",
        "          compression:\n",
        "            Compression algorithm used during allreduce to reduce the amount\n",
        "            of data sent during the each parameter update step.  Defaults to\n",
        "            not using compression.\n",
        "          sparse_as_dense:\n",
        "            Treat all sparse gradients as dense tensors.  This can help improve\n",
        "            performance and memory utilization if the original sparse gradient\n",
        "            has high density.  Defaults to false.\n",
        "        \"\"\"\n",
        "        if name is None:\n",
        "            name = \"Distributed{}\".format(type(optimizer).__name__)\n",
        "\n",
        "        self._optimizer = optimizer\n",
        "        self._device_dense = device_dense\n",
        "        self._device_sparse = device_sparse\n",
        "        self._compression = compression\n",
        "        self._sparse_as_dense = sparse_as_dense\n",
        "\n",
        "        def allreduce_grads(grads_and_vars):\n",
        "            with tf.name_scope(self._name + \"_Allreduce\"):\n",
        "                return [allreduce(grad*self._optimizer._learning_rate, var, self._optimizer,\n",
        "                                  device_dense=self._device_dense,\n",
        "                                  device_sparse=self._device_sparse,\n",
        "                                  compression=self._compression)/(self._optimizer._learning_rate + tf.constant(1e-5, dtype=tf.float32))\n",
        "                        if grad is not None else grad\n",
        "                        for grad, var in grads_and_vars], [var for grad, var in grads_and_vars]\n",
        "\n",
        "        if _executing_eagerly():\n",
        "            self._allreduce_grads = tf.contrib.eager.defun(allreduce_grads)\n",
        "        else:\n",
        "            self._allreduce_grads = allreduce_grads\n",
        "\n",
        "        super(DistributedOptimizer, self).__init__(\n",
        "            name=name, use_locking=use_locking)\n",
        "\n",
        "#    def _create_slots(self, var_list):\n",
        "#      for v in var_list:\n",
        "#        self._zeros_slot(v, \"memory\", \"error\")\n",
        "\n",
        "    def compute_gradients(self, *args, **kwargs):\n",
        "        \"\"\"Compute gradients of all trainable variables.\n",
        "        See Optimizer.compute_gradients() for more info.\n",
        "        In DistributedOptimizer, compute_gradients() is overriden to also\n",
        "        allreduce the gradients before returning them.\n",
        "        \"\"\"\n",
        "        grads_and_vars = self._optimizer.compute_gradients(*args, **kwargs)\n",
        "        if size() > 1:\n",
        "#            grads, vars = zip(*gradients)\n",
        "            avg_grads, vars = self._allreduce_grads(grads_and_vars)\n",
        "            return list(zip(avg_grads, vars))\n",
        "        else:\n",
        "            return grads_and_vars\n",
        "\n",
        "    def apply_gradients(self, *args, **kwargs):\n",
        "        \"\"\"Calls this same method on the underlying optimizer.\"\"\"\n",
        "        return self._optimizer.apply_gradients(*args, **kwargs)\n",
        "\n",
        "    def get_slot(self, *args, **kwargs):\n",
        "        \"\"\"Calls this same method on the underlying optimizer.\"\"\"\n",
        "        return self._optimizer.get_slot(*args, **kwargs)\n",
        "\n",
        "    def get_slot_names(self, *args, **kwargs):\n",
        "        \"\"\"Calls this same method on the underlying optimizer.\"\"\"\n",
        "        return self._optimizer.get_slot_names(*args, **kwargs)\n",
        "\n",
        "    def variables(self, *args, **kwargs):\n",
        "        \"\"\"Calls this same method on the underlying optimizer.\"\"\"\n",
        "        return self._optimizer.variables(*args, **kwargs)"
      ],
      "metadata": {
        "id": "OASCtUzMgrnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_resnet.py"
      ],
      "metadata": {
        "id": "XpS2ooWFenQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"\n",
        "Changelog:\n",
        "1.2\n",
        "  - Add logging to file and console\n",
        "1.1\n",
        "  - Center crop evaluation images\n",
        "  - Enable LARC learning rate control\n",
        "  - Correctly order UPDATE_OPS and global_step update during training.\n",
        "  - Set default learning rate policy to polynomial decay.\n",
        "  - Add cmd line options for checkpoint and summary intervals.\n",
        "  - Add loss scaling.\n",
        "  - Scale resnet learning rate by batch size.\n",
        "1.0\n",
        "  - Initial version\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "from builtins import range\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.ops import data_flow_ops\n",
        "from tensorflow.python.ops import init_ops\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import logging\n",
        "from collections import defaultdict\n",
        "import argparse\n",
        "\n",
        "import pickle\n",
        "\n",
        "try:\n",
        "    import horovod.tensorflow as hvd\n",
        "except:\n",
        "    print(\"Failed to import horovod module. \"\n",
        "          \"%s is intended for use with Uber's Horovod distributed training \"\n",
        "          \"framework. To create a Docker image with Horovod support see \"\n",
        "          \"docker-examples/Dockerfile.horovod.\" % __file__)\n",
        "    raise\n",
        "\n",
        "print(tf.__file__)\n",
        "print(hvd.__file__)\n",
        "\n",
        "__version__ = \"1.0\"\n",
        "\n",
        "def tensorflow_version_tuple():\n",
        "    v = tf.__version__\n",
        "    major, minor, patch = v.split('.')\n",
        "    return (int(major), int(minor), patch)\n",
        "\n",
        "hvd.init()\n",
        "\n",
        "def print_r0(*args, **kwargs):\n",
        "    if hvd.rank() == 0:\n",
        "        print(*args, **kwargs)\n",
        "\n",
        "def float32_variable_storage_getter(getter, name, shape=None, dtype=None,\n",
        "                                    initializer=None, regularizer=None,\n",
        "                                    trainable=True,\n",
        "                                    *args, **kwargs):\n",
        "    storage_dtype = tf.float32 if trainable else dtype\n",
        "    variable = getter(name, shape, dtype=storage_dtype,\n",
        "                      initializer=initializer, regularizer=regularizer,\n",
        "                      trainable=trainable,\n",
        "                      *args, **kwargs)\n",
        "    if trainable and dtype != tf.float32:\n",
        "        variable = tf.cast(variable, dtype)\n",
        "    return variable\n",
        "\n",
        "class GPUNetworkBuilder(object):\n",
        "    \"\"\"This class provides convenient methods for constructing feed-forward\n",
        "    networks with internal data layout of 'NCHW'.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 is_training,\n",
        "                 dtype=tf.float32,\n",
        "                 activation='RELU',\n",
        "                 use_batch_norm=True,\n",
        "                 batch_norm_config = {'decay':   0.9,\n",
        "                                      'epsilon': 1e-4,\n",
        "                                      'scale':   True,\n",
        "                                      'zero_debias_moving_mean': False}):\n",
        "        self.dtype             = dtype\n",
        "        self.activation_func   = activation\n",
        "        self.is_training       = is_training\n",
        "        self.use_batch_norm    = use_batch_norm\n",
        "        self.batch_norm_config = batch_norm_config\n",
        "        self._layer_counts     = defaultdict(lambda: 0)\n",
        "    def _count_layer(self, layer_type):\n",
        "        idx  = self._layer_counts[layer_type]\n",
        "        name = layer_type + str(idx)\n",
        "        self._layer_counts[layer_type] += 1\n",
        "        return name\n",
        "    def _get_variable(self, name, shape, dtype=None,\n",
        "                      initializer=None, seed=None):\n",
        "        if dtype is None:\n",
        "            dtype = self.dtype\n",
        "        if initializer is None:\n",
        "            initializer = init_ops.glorot_uniform_initializer(seed=seed)\n",
        "        elif (isinstance(initializer, float) or\n",
        "              isinstance(initializer, int)):\n",
        "            initializer = tf.constant_initializer(float(initializer))\n",
        "        return tf.get_variable(name, shape, dtype, initializer)\n",
        "    def _to_nhwc(self, x):\n",
        "        return tf.transpose(x, [0,2,3,1])\n",
        "    def _from_nhwc(self, x):\n",
        "        return tf.transpose(x, [0,3,1,2])\n",
        "    def _bias(self, input_layer):\n",
        "        num_outputs = input_layer.get_shape().as_list()[1]\n",
        "        biases = self._get_variable('biases', [num_outputs], input_layer.dtype,\n",
        "                                    initializer=0)\n",
        "        if len(input_layer.get_shape()) == 4:\n",
        "            return tf.nn.bias_add(input_layer, biases,\n",
        "                                  data_format='NCHW')\n",
        "        else:\n",
        "            return input_layer + biases\n",
        "    def _batch_norm(self, input_layer, scope):\n",
        "        return tf.contrib.layers.batch_norm(input_layer,\n",
        "                                            is_training=self.is_training,\n",
        "                                            scope=scope,\n",
        "                                            data_format='NCHW',\n",
        "                                            fused=True,\n",
        "                                            **self.batch_norm_config)\n",
        "    def _bias_or_batch_norm(self, input_layer, scope, use_batch_norm):\n",
        "        if use_batch_norm is None:\n",
        "            use_batch_norm = self.use_batch_norm\n",
        "        if use_batch_norm:\n",
        "            return self._batch_norm(input_layer, scope)\n",
        "        else:\n",
        "            return self._bias(input_layer)\n",
        "    def input_layer(self, input_layer):\n",
        "        \"\"\"Converts input data into the internal format\"\"\"\n",
        "        x = self._from_nhwc(input_layer)\n",
        "        x = tf.cast(x, self.dtype)\n",
        "        # Rescale and shift to [-1,1]\n",
        "        x = x * (1./127.5) - 1\n",
        "        return x\n",
        "    def conv(self, input_layer, num_filters, filter_size,\n",
        "             filter_strides=(1,1), padding='SAME',\n",
        "             activation=None, use_batch_norm=None):\n",
        "        \"\"\"Applies a 2D convolution layer that includes bias or batch-norm\n",
        "        and an activation function.\n",
        "        \"\"\"\n",
        "        num_inputs = input_layer.get_shape().as_list()[1]\n",
        "        kernel_shape = [filter_size[0], filter_size[1],\n",
        "                        num_inputs, num_filters]\n",
        "        strides = [1, 1, filter_strides[0], filter_strides[1]]\n",
        "        with tf.variable_scope(self._count_layer('conv')) as scope:\n",
        "            kernel = self._get_variable('weights', kernel_shape,\n",
        "                                        input_layer.dtype)\n",
        "            if padding == 'SAME_RESNET': # ResNet models require custom padding\n",
        "                kh, kw = filter_size\n",
        "                rate = 1\n",
        "                kernel_size_effective = kh + (kw - 1) * (rate - 1)\n",
        "                pad_total = kernel_size_effective - 1\n",
        "                pad_beg = pad_total // 2\n",
        "                pad_end = pad_total - pad_beg\n",
        "                padding = [[0, 0], [0, 0],\n",
        "                           [pad_beg, pad_end], [pad_beg, pad_end]]\n",
        "                input_layer = tf.pad(input_layer, padding)\n",
        "                padding = 'VALID'\n",
        "            x = tf.nn.conv2d(input_layer, kernel, strides,\n",
        "                             padding=padding, data_format='NCHW')\n",
        "            x = self._bias_or_batch_norm(x, scope, use_batch_norm)\n",
        "            x = self.activate(x, activation)\n",
        "            return x\n",
        "    def deconv(self, input_layer, num_filters, filter_size,\n",
        "               filter_strides=(2,2), padding='SAME',\n",
        "               activation=None, use_batch_norm=None):\n",
        "        \"\"\"Applies a 'transposed convolution' layer that includes bias or\n",
        "        batch-norm and an activation function.\n",
        "        \"\"\"\n",
        "        num_inputs  = input_layer.get_shape().as_list()[1]\n",
        "        ih, iw      = input_layer.get_shape().as_list()[2:]\n",
        "        output_shape = [-1, num_filters,\n",
        "                        ih*filter_strides[0], iw*filter_strides[1]]\n",
        "        kernel_shape = [filter_size[0], filter_size[1],\n",
        "                        num_filters, num_inputs]\n",
        "        strides = [1, 1, filter_strides[0], filter_strides[1]]\n",
        "        with tf.variable_scope(self._count_layer('deconv')) as scope:\n",
        "            kernel = self._get_variable('weights', kernel_shape,\n",
        "                                        input_layer.dtype)\n",
        "            x = tf.nn.conv2d_transpose(input_layer, kernel, output_shape,\n",
        "                                       strides, padding=padding,\n",
        "                                       data_format='NCHW')\n",
        "            x = self._bias_or_batch_norm(x, scope, use_batch_norm)\n",
        "            x = self.activate(x, activation)\n",
        "            return x\n",
        "    def activate(self, input_layer, funcname=None):\n",
        "        \"\"\"Applies an activation function\"\"\"\n",
        "        if isinstance(funcname, tuple):\n",
        "            funcname = funcname[0]\n",
        "            params = funcname[1:]\n",
        "        if funcname is None:\n",
        "            funcname = self.activation_func\n",
        "        if funcname == 'LINEAR':\n",
        "            return input_layer\n",
        "        activation_map = {\n",
        "            'RELU':    tf.nn.relu,\n",
        "            'RELU6':   tf.nn.relu6,\n",
        "            'ELU':     tf.nn.elu,\n",
        "            'SIGMOID': tf.nn.sigmoid,\n",
        "            'TANH':    tf.nn.tanh,\n",
        "            'LRELU':   lambda x, name: tf.maximum(params[0]*x, x, name=name)\n",
        "        }\n",
        "        return activation_map[funcname](input_layer, name=funcname.lower())\n",
        "    def pool(self, input_layer, funcname, window_size,\n",
        "                 window_strides=(2,2),\n",
        "                 padding='VALID'):\n",
        "        \"\"\"Applies spatial pooling\"\"\"\n",
        "        pool_map = {\n",
        "            'MAX': tf.nn.max_pool,\n",
        "            'AVG': tf.nn.avg_pool\n",
        "        }\n",
        "        kernel_size    = [1, 1, window_size[0], window_size[1]]\n",
        "        kernel_strides = [1, 1, window_strides[0], window_strides[1]]\n",
        "        return pool_map[funcname](input_layer, kernel_size, kernel_strides,\n",
        "                                  padding, data_format='NCHW',\n",
        "                                  name=funcname.lower())\n",
        "    def project(self, input_layer, num_outputs, height, width,\n",
        "                activation=None):\n",
        "        \"\"\"Linearly projects to an image-like tensor\"\"\"\n",
        "        with tf.variable_scope(self._count_layer('project')):\n",
        "            x = self.fully_connected(input_layer, num_outputs*height*width,\n",
        "                                     activation=activation)\n",
        "            x = tf.reshape(x, [-1, num_outputs, height, width])\n",
        "            return x\n",
        "    def flatten(self, input_layer):\n",
        "        \"\"\"Flattens the spatial and channel dims into a single dim (4D->2D)\"\"\"\n",
        "        # Note: This ensures the output order matches that of NHWC networks\n",
        "        input_layer = self._to_nhwc(input_layer)\n",
        "        input_shape = input_layer.get_shape().as_list()\n",
        "        num_inputs  = input_shape[1]*input_shape[2]*input_shape[3]\n",
        "        return tf.reshape(input_layer, [-1, num_inputs], name='flatten')\n",
        "    def spatial_avg(self, input_layer):\n",
        "        \"\"\"Averages over spatial dimensions (4D->2D)\"\"\"\n",
        "        return tf.reduce_mean(input_layer, [2, 3], name='spatial_avg')\n",
        "    def fully_connected(self, input_layer, num_outputs, activation=None):\n",
        "        \"\"\"Applies a fully-connected set of weights\"\"\"\n",
        "        num_inputs = input_layer.get_shape().as_list()[1]\n",
        "        kernel_size = [num_inputs, num_outputs]\n",
        "        with tf.variable_scope(self._count_layer('fully_connected')):\n",
        "            kernel = self._get_variable('weights', kernel_size,\n",
        "                                        input_layer.dtype)\n",
        "            x = tf.matmul(input_layer, kernel)\n",
        "            x = self._bias(x)\n",
        "            x = self.activate(x, activation)\n",
        "            return x\n",
        "    def inception_module(self, input_layer, name, cols):\n",
        "        \"\"\"Applies an inception module with a given form\"\"\"\n",
        "        with tf.name_scope(name):\n",
        "            col_layers      = []\n",
        "            col_layer_sizes = []\n",
        "            for c, col in enumerate(cols):\n",
        "                col_layers.append([])\n",
        "                col_layer_sizes.append([])\n",
        "                x = input_layer\n",
        "                for l, layer in enumerate(col):\n",
        "                    ltype, args = layer[0], layer[1:]\n",
        "                    if   ltype == 'conv': x = self.conv(x, *args)\n",
        "                    elif ltype == 'pool': x = self.pool(x, *args)\n",
        "                    elif ltype == 'share':\n",
        "                        # Share matching layer from previous column\n",
        "                        x = col_layers[c-1][l]\n",
        "                    else: raise KeyError(\"Invalid layer type for \" +\n",
        "                                         \"inception module: '%s'\" % ltype)\n",
        "                    col_layers[c].append(x)\n",
        "            catdim  = 1\n",
        "            catvals = [layers[-1] for layers in col_layers]\n",
        "            x = tf.concat(catvals, catdim)\n",
        "            return x\n",
        "    def residual(self, input_layer, net, scale=1.0, activation='RELU'):\n",
        "        \"\"\"Applies a residual layer\"\"\"\n",
        "        input_size     = input_layer.get_shape().as_list()\n",
        "        num_inputs     = input_size[1]\n",
        "        output_layer   = scale*net(self, input_layer)\n",
        "        output_size    = output_layer.get_shape().as_list()\n",
        "        num_outputs    = output_size[1]\n",
        "        kernel_strides = (input_size[2]//output_size[2],\n",
        "                          input_size[3]//output_size[3])\n",
        "        with tf.name_scope('residual'):\n",
        "            if (num_outputs != num_inputs or\n",
        "                kernel_strides[0] != 1 or\n",
        "                kernel_strides[1] != 1):\n",
        "                input_layer = self.conv(input_layer, num_outputs, [1, 1],\n",
        "                                        kernel_strides, activation='LINEAR')\n",
        "            x = self.activate(input_layer + output_layer, activation)\n",
        "            return x\n",
        "    def dropout(self, input_layer, keep_prob=0.5):\n",
        "        \"\"\"Applies a dropout layer if is_training\"\"\"\n",
        "        if self.is_training:\n",
        "            dtype = input_layer.dtype\n",
        "            with tf.variable_scope(self._count_layer('dropout')):\n",
        "                keep_prob_tensor = tf.constant(keep_prob, dtype=dtype)\n",
        "                return tf.nn.dropout(input_layer, keep_prob_tensor)\n",
        "        else:\n",
        "            return input_layer\n",
        "\n",
        "def deserialize_image_record(record):\n",
        "    feature_map = {\n",
        "        'image/encoded':          tf.FixedLenFeature([ ], tf.string, ''),\n",
        "        'image/class/label':      tf.FixedLenFeature([1], tf.int64,  -1),\n",
        "        'image/class/text':       tf.FixedLenFeature([ ], tf.string, ''),\n",
        "        'image/object/bbox/xmin': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'image/object/bbox/ymin': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'image/object/bbox/xmax': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'image/object/bbox/ymax': tf.VarLenFeature(dtype=tf.float32)\n",
        "    }\n",
        "    with tf.name_scope('deserialize_image_record'):\n",
        "        obj = tf.parse_single_example(record, feature_map)\n",
        "        imgdata = obj['image/encoded']\n",
        "        label   = tf.cast(obj['image/class/label'], tf.int32)\n",
        "        bbox    = tf.stack([obj['image/object/bbox/%s'%x].values\n",
        "                            for x in ['ymin', 'xmin', 'ymax', 'xmax']])\n",
        "        bbox = tf.transpose(tf.expand_dims(bbox, 0), [0,2,1])\n",
        "        text    = obj['image/class/text']\n",
        "        return imgdata, label, bbox, text\n",
        "\n",
        "def decode_jpeg(imgdata, channels=3):\n",
        "    return tf.image.decode_jpeg(imgdata, channels=channels,\n",
        "                                fancy_upscaling=False,\n",
        "                                dct_method='INTEGER_FAST')\n",
        "\n",
        "def decode_png(imgdata, channels=3):\n",
        "    return tf.image.decode_png(imgdata, channels=channels)\n",
        "\n",
        "def random_crop_and_resize_image(image, bbox, height, width):\n",
        "    with tf.name_scope('random_crop_and_resize'):\n",
        "        if FLAGS.eval:\n",
        "            image = tf.image.central_crop(image, 224./256.)\n",
        "        else:\n",
        "            bbox_begin, bbox_size, distorted_bbox = tf.image.sample_distorted_bounding_box(\n",
        "                tf.shape(image),\n",
        "                bounding_boxes=bbox,\n",
        "                min_object_covered=0.1,\n",
        "                aspect_ratio_range=[0.8, 1.25],\n",
        "                area_range=[0.1, 1.0],\n",
        "                max_attempts=100,\n",
        "                use_image_if_no_bounding_boxes=True)\n",
        "            # Crop the image to the distorted bounding box\n",
        "            image = tf.slice(image, bbox_begin, bbox_size)\n",
        "        # Resize to the desired output size\n",
        "        image = tf.image.resize_images(\n",
        "            image,\n",
        "            [height, width],\n",
        "            tf.image.ResizeMethod.BILINEAR,\n",
        "            align_corners=False)\n",
        "        image.set_shape([height, width, 3])\n",
        "        return image\n",
        "\n",
        "def distort_image_color(image, order):\n",
        "    with tf.name_scope('distort_color'):\n",
        "        image /= 255.\n",
        "        brightness = lambda img: tf.image.random_brightness(img, max_delta=32. / 255.)\n",
        "        saturation = lambda img: tf.image.random_saturation(img, lower=0.5, upper=1.5)\n",
        "        hue        = lambda img: tf.image.random_hue(img, max_delta=0.2)\n",
        "        contrast   = lambda img: tf.image.random_contrast(img, lower=0.5, upper=1.5)\n",
        "        if order == 0: ops = [brightness, saturation, hue, contrast]\n",
        "        else:          ops = [brightness, contrast, saturation, hue]\n",
        "        for op in ops:\n",
        "            image = op(image)\n",
        "        # The random_* ops do not necessarily clamp the output range\n",
        "        image = tf.clip_by_value(image, 0.0, 1.0)\n",
        "        # Restore the original scaling\n",
        "        image *= 255\n",
        "        return image\n",
        "\n",
        "class DummyPreprocessor(object):\n",
        "    def __init__(self, height, width, batch, nclass):\n",
        "        self.height = height\n",
        "        self.width  = width\n",
        "        self.batch = batch\n",
        "        self.nclass = nclass\n",
        "\n",
        "class ImagePreprocessor(object):\n",
        "    def __init__(self, height, width, subset='train', dtype=tf.uint8):\n",
        "        self.height = height\n",
        "        self.width  = width\n",
        "        self.subset = subset\n",
        "        self.dtype = dtype\n",
        "        self.nsummary = 10 # Max no. images to generate summaries for\n",
        "    def preprocess(self, imgdata, bbox, thread_id):\n",
        "        with tf.name_scope('preprocess_image'):\n",
        "            try:\n",
        "                image = decode_jpeg(imgdata)\n",
        "            except:\n",
        "                image = decode_png(imgdata)\n",
        "            if thread_id < self.nsummary:\n",
        "                image_with_bbox = tf.image.draw_bounding_boxes(\n",
        "                    tf.expand_dims(tf.to_float(image), 0), bbox)\n",
        "                tf.summary.image('original_image_and_bbox', image_with_bbox)\n",
        "            image = random_crop_and_resize_image(image, bbox,\n",
        "                                                 self.height, self.width)\n",
        "            if thread_id < self.nsummary:\n",
        "                tf.summary.image('cropped_resized_image',\n",
        "                                 tf.expand_dims(image, 0))\n",
        "            if not FLAGS.eval:\n",
        "                image = tf.image.random_flip_left_right(image)\n",
        "            if thread_id < self.nsummary:\n",
        "                tf.summary.image('flipped_image',\n",
        "                                 tf.expand_dims(image, 0))\n",
        "            if FLAGS.distort_color and not FLAGS.eval:\n",
        "                image = distort_image_color(image, order=thread_id%2)\n",
        "                if thread_id < self.nsummary:\n",
        "                    tf.summary.image('distorted_color_image',\n",
        "                                     tf.expand_dims(image, 0))\n",
        "        return image\n",
        "    def minibatch(self, batch_size):\n",
        "        record_input = data_flow_ops.RecordInput(\n",
        "            file_pattern=os.path.join(FLAGS.data_dir, '%s-*' % self.subset),\n",
        "            parallelism=64,\n",
        "            seed=301+hvd.rank(),\n",
        "            # Note: This causes deadlock during init if larger than dataset\n",
        "            buffer_size=FLAGS.input_buffer_size,\n",
        "            batch_size=batch_size)\n",
        "        records = record_input.get_yield_op()\n",
        "        # Split batch into individual images\n",
        "        records = tf.split(records, batch_size, 0)\n",
        "        records = [tf.reshape(record, []) for record in records]\n",
        "        # Deserialize and preprocess images into batches for each device\n",
        "        images = []\n",
        "        labels = []\n",
        "        with tf.name_scope('input_pipeline'):\n",
        "            for i, record in enumerate(records):\n",
        "                imgdata, label, bbox, text = deserialize_image_record(record)\n",
        "                image = self.preprocess(imgdata, bbox, thread_id=i)\n",
        "                label -= 1 # Change to 0-based (don't use background class)\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "            # Stack images back into a single tensor\n",
        "            images = tf.parallel_stack(images)\n",
        "            labels = tf.concat(labels, 0)\n",
        "            images = tf.reshape(images, [-1, self.height, self.width, 3])\n",
        "            images = tf.clip_by_value(images, 0., 255.)\n",
        "            images = tf.cast(images, self.dtype)\n",
        "        return images, labels\n",
        "\n",
        "def stage(tensors):\n",
        "    \"\"\"Stages the given tensors in a StagingArea for asynchronous put/get.\n",
        "    \"\"\"\n",
        "    stage_area = data_flow_ops.StagingArea(\n",
        "        dtypes=[tensor.dtype       for tensor in tensors],\n",
        "        shapes=[tensor.get_shape() for tensor in tensors])\n",
        "    put_op      = stage_area.put(tensors)\n",
        "    get_tensors = stage_area.get()\n",
        "\n",
        "    get_tensors = [tf.reshape(gt, t.get_shape())\n",
        "                   for (gt,t) in zip(get_tensors, tensors)]\n",
        "    return put_op, get_tensors\n",
        "\n",
        "\n",
        "class FeedForwardTrainer(object):\n",
        "    def __init__(self, preprocessor, loss_func, nstep_per_epoch=None, sync_period=1):\n",
        "        self.image_preprocessor = preprocessor\n",
        "        self.loss_func          = loss_func\n",
        "        with tf.device('/cpu:0'):\n",
        "            self.global_step = tf.get_variable(\n",
        "                'global_step', [],\n",
        "                initializer=tf.constant_initializer(0),\n",
        "                dtype=tf.int64,\n",
        "                trainable=False)\n",
        "        if FLAGS.lr_decay_policy == 'poly':\n",
        "            self.learning_rate = tf.train.polynomial_decay(\n",
        "                FLAGS.learning_rate,\n",
        "                self.global_step,\n",
        "                decay_steps=FLAGS.num_epochs*nstep_per_epoch,\n",
        "                end_learning_rate=0.,\n",
        "                power=FLAGS.lr_poly_power,\n",
        "                cycle=False)\n",
        "        else:\n",
        "            boundary_epochs = [30, 60, 90, 120]\n",
        "            decay_rates = [1, 0.1, 0.01, 0.001, 1e-4]\n",
        "            base_lr = 0.128\n",
        "            batch_size = hvd.size()*256\n",
        "            batch_denom = 1024\n",
        "            num_images = 1281167\n",
        "            batches_per_epoch = num_images // batch_size \n",
        "            initial_learning_rate = base_lr * batch_size / batch_denom\n",
        "            self.boundaries = [(int(batches_per_epoch * epoch)//sync_period)*sync_period for epoch in boundary_epochs]\n",
        "            vals = [initial_learning_rate * decay for decay in decay_rates]\n",
        "\n",
        "            def learning_rate_fn(global_step):\n",
        "                lr = tf.train.piecewise_constant(global_step, self.boundaries, vals)\n",
        "                warmup_steps = int(batches_per_epoch * 5)\n",
        "                warmup_lr = (\n",
        "                    initial_learning_rate * tf.cast(global_step, tf.float32) / tf.cast(\n",
        "                    warmup_steps, tf.float32))\n",
        "                return tf.cond(global_step < warmup_steps, lambda: warmup_lr, lambda: lr)\n",
        "\n",
        "            self.learning_rate = learning_rate_fn(self.global_step)\n",
        "\n",
        "    def training_step(self, batch_size, sync_weights, wipe_memory):\n",
        "        if type(self.image_preprocessor) is not DummyPreprocessor:\n",
        "            with tf.device('/cpu:0'):\n",
        "                images, labels = self.image_preprocessor.minibatch(batch_size)\n",
        "                # Stage images on the host\n",
        "                preload_op, (images, labels) = stage([images, labels])\n",
        "            with tf.device('/gpu:0'):\n",
        "                # Copy images from host to device\n",
        "                gpucopy_op, (images, labels) = stage([images, labels])\n",
        "        else:\n",
        "            with tf.device('/gpu:0'):\n",
        "                input_shape = [self.image_preprocessor.batch, \n",
        "                               self.image_preprocessor.height,\n",
        "                               self.image_preprocessor.width,\n",
        "                               3]\n",
        "                images = tf.truncated_normal(\n",
        "                    input_shape,\n",
        "                    dtype=tf.float32,\n",
        "                    stddev=1.e-1,\n",
        "                    name='synthetic_images')\n",
        "                labels = tf.random_uniform(\n",
        "                    [self.image_preprocessor.batch],\n",
        "                    minval=0,\n",
        "                    maxval=self.image_preprocessor.nclass-1,\n",
        "                    dtype=tf.int32,\n",
        "                    name='synthetic_labels')\n",
        "                preload_op, (images, labels) = stage([images, labels])\n",
        "                gpucopy_op = None\n",
        "\n",
        "        with tf.device('/gpu:0'):\n",
        "            # Evaluate the loss and compute the gradients\n",
        "            with tf.variable_scope(\n",
        "                    'GPU_0',\n",
        "                    # Force all variables to be stored as float32\n",
        "                    custom_getter=float32_variable_storage_getter) as var_scope:\n",
        "                loss, logits = self.loss_func(images, labels, var_scope)\n",
        " \n",
        "        with tf.device('/cpu:0'): # No in_top_k implem on GPU\n",
        "            top1 = tf.reduce_mean(\n",
        "                tf.cast(tf.nn.in_top_k(logits, labels, 1), tf.float32))\n",
        "            top5 = tf.reduce_mean(\n",
        "                tf.cast(tf.nn.in_top_k(logits, labels, 5), tf.float32))\n",
        "\n",
        "            averager = tf.train.ExponentialMovingAverage(0.90, name='loss_avg',\n",
        "                                                         zero_debias=True)\n",
        "            avg_op = averager.apply([loss])\n",
        "            loss_avg = averager.average(loss)\n",
        "            # Note: This must be done _after_ the averager.average() call\n",
        "            #         because it changes total_loss into a new object.\n",
        "            with tf.control_dependencies([avg_op]):\n",
        "                total_loss     = tf.identity(loss)\n",
        "                total_loss_avg = tf.identity(loss_avg)\n",
        "            tf.summary.scalar('total_loss_raw', total_loss)\n",
        "            tf.summary.scalar('total_loss_avg', total_loss_avg)\n",
        "            tf.summary.scalar('Top-1_accuracy', 100.*top1)\n",
        "            tf.summary.scalar('Top-5_accuracy', 100.*top5)\n",
        "            tf.summary.scalar('learning_rate', self.learning_rate)\n",
        "\n",
        "        # Apply the gradients to optimize the loss function\n",
        "        with tf.device('/gpu:0'):\n",
        "            opt = tf.train.MomentumOptimizer(self.learning_rate, FLAGS.momentum,\n",
        "                                             use_nesterov=True)\n",
        "            opt = hvd.DistributedOptimizer(opt)\n",
        "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) or []\n",
        "            with tf.control_dependencies(update_ops):\n",
        "                if FLAGS.loss_scale != 1:\n",
        "                    loss = loss * float(FLAGS.loss_scale)\n",
        "                gradvars = opt._optimizer.compute_gradients(loss,\n",
        "                    gate_gradients=tf.train.Optimizer.GATE_NONE)\n",
        "                if FLAGS.loss_scale != 1:\n",
        "                    inv_scale = 1. / float(FLAGS.loss_scale)\n",
        "                    gradvars = [(grad * inv_scale, var)\n",
        "                                for grad, var in gradvars]\n",
        "\n",
        "            local_update_op = lambda: opt.apply_gradients(gradvars)\n",
        "\n",
        "            def weight_sync_op():\n",
        "                apply_op = opt.apply_gradients(gradvars)\n",
        "                with tf.control_dependencies([apply_op]):\n",
        "                    all_updates = []\n",
        "                    for _, var in gradvars:\n",
        "                        last_var = opt._get_or_make_slot(var, var.initialized_value(), 'prev_var', 'last_var')  \n",
        "                        new_var = last_var + hvd.allreduce(var-last_var, var, opt, wipe_memory)\n",
        "                        all_updates.append(var.assign(new_var))\n",
        "                        all_updates.append(last_var.assign(new_var))\n",
        "                    return tf.group(*all_updates)\n",
        "\n",
        "            train_op = tf.cond(sync_weights, true_fn=weight_sync_op, false_fn=local_update_op)\n",
        "\n",
        "#            train_op = opt.apply_gradients(gradvars)\n",
        "\n",
        "        with tf.device('/cpu:0'):\n",
        "            with tf.control_dependencies([train_op]):\n",
        "                increment_global_step_op = tf.assign_add(self.global_step, 1)\n",
        "        self.enqueue_ops = []\n",
        "        self.enqueue_ops.append(preload_op)\n",
        "        if gpucopy_op is not None:\n",
        "            self.enqueue_ops.append(gpucopy_op)\n",
        "        all_training_ops = (self.enqueue_ops + [increment_global_step_op])\n",
        "        return total_loss_avg, self.learning_rate, all_training_ops\n",
        "    def init(self, sess):\n",
        "        init_op = tf.global_variables_initializer()\n",
        "        sess.run(init_op)\n",
        "    def sync(self, sess):\n",
        "        sync_op = hvd.broadcast_global_variables(0)\n",
        "        sess.run(sync_op)\n",
        "    def prefill_pipeline(self, sess):\n",
        "        # Pre-fill the input pipeline with data\n",
        "        for i in range(len(self.enqueue_ops)):\n",
        "            sess.run(self.enqueue_ops[:i+1])\n",
        "\n",
        "class FeedForwardEvaluator(object):\n",
        "    def __init__(self, preprocessor, eval_func):\n",
        "        self.eval_func          = eval_func\n",
        "        self.image_preprocessor = preprocessor\n",
        "    def evaluation_step(self, batch_size):\n",
        "        with tf.device('/cpu:0'):\n",
        "            images, labels = self.image_preprocessor.minibatch(batch_size)\n",
        "            # Stage images on the host\n",
        "            preload_op, (images, labels) = stage([images, labels])\n",
        "        with tf.device('/gpu:0'):\n",
        "            # Copy images from host to device\n",
        "            gpucopy_op, (images, labels) = stage([images, labels])\n",
        "            # Evaluate the loss and compute the gradients\n",
        "            with tf.variable_scope('GPU_0') as var_scope:\n",
        "                top1, top5 = self.eval_func(images, labels, var_scope)\n",
        "        self.enqueue_ops = [preload_op, gpucopy_op]\n",
        "        return top1, top5, self.enqueue_ops\n",
        "    def prefill_pipeline(self, sess):\n",
        "        # Pre-fill the input pipeline with data\n",
        "        for i in range(len(self.enqueue_ops)):\n",
        "            sess.run(self.enqueue_ops[:i+1])\n",
        "\n",
        "def inference_trivial(net, input_layer):\n",
        "    \"\"\"A trivial model for benchmarking input pipeline performance\"\"\"\n",
        "    net.use_batch_norm = False\n",
        "    x = net.input_layer(input_layer)\n",
        "    x = net.flatten(x)\n",
        "    x = net.fully_connected(x, 1)\n",
        "    return x\n",
        "\n",
        "def inference_lenet5(net, input_layer):\n",
        "    \"\"\"Tiny network matching TF's MNIST tutorial model\"\"\"\n",
        "    net.use_batch_norm = False\n",
        "    x = net.input_layer(input_layer)\n",
        "    x = net.conv(x, 32,    (5,5))\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    x = net.conv(x, 64,    (5,5))\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    x = net.flatten(x)\n",
        "    x = net.fully_connected(x, 512)\n",
        "    return x\n",
        "\n",
        "def inference_overfeat(net, input_layer):\n",
        "    net.use_batch_norm = False\n",
        "    x = net.input_layer(input_layer)\n",
        "    x = net.conv(x, 96,   (11,11), (4,4), 'VALID')\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    x = net.conv(x, 256,   (5,5), (1,1), 'VALID')\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    x = net.conv(x, 512,   (3,3))\n",
        "    x = net.conv(x, 1024,  (3,3))\n",
        "    x = net.conv(x, 1024,  (3,3))\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    x = net.flatten(x)\n",
        "    x = net.fully_connected(x, 3072)\n",
        "    x = net.fully_connected(x, 4096)\n",
        "    return x\n",
        "\n",
        "def inference_alexnet_owt(net, input_layer):\n",
        "    \"\"\"Alexnet One Weird Trick model\n",
        "    https://arxiv.org/abs/1404.5997\n",
        "    \"\"\"\n",
        "    net.use_batch_norm = False\n",
        "    x = net.input_layer(input_layer)\n",
        "    # Note: VALID requires padding the images by 3 in width and height\n",
        "    x = net.conv(x, 64, (11,11), (4,4), 'VALID')\n",
        "    x = net.pool(x, 'MAX', (3,3))\n",
        "    x = net.conv(x, 192,   (5,5))\n",
        "    x = net.pool(x, 'MAX', (3,3))\n",
        "    x = net.conv(x, 384,   (3,3))\n",
        "    x = net.conv(x, 256,   (3,3))\n",
        "    x = net.conv(x, 256,   (3,3))\n",
        "    x = net.pool(x, 'MAX', (3,3))\n",
        "    x = net.flatten(x)\n",
        "    x = net.fully_connected(x, 4096)\n",
        "    x = net.dropout(x)\n",
        "    x = net.fully_connected(x, 4096)\n",
        "    x = net.dropout(x)\n",
        "    return x\n",
        "\n",
        "def inference_vgg_impl(net, input_layer, layer_counts):\n",
        "    net.use_batch_norm = False\n",
        "    x = net.input_layer(input_layer)\n",
        "    for _ in range(layer_counts[0]): x = net.conv(x,  64, (3,3))\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    for _ in range(layer_counts[1]): x = net.conv(x, 128, (3,3))\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    for _ in range(layer_counts[2]): x = net.conv(x, 256, (3,3))\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    for _ in range(layer_counts[3]): x = net.conv(x, 512, (3,3))\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    for _ in range(layer_counts[4]): x = net.conv(x, 512, (3,3))\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    x = net.flatten(x)\n",
        "    x = net.fully_connected(x, 4096)\n",
        "    x = net.fully_connected(x, 4096)\n",
        "    return x\n",
        "def inference_vgg(net, input_layer, nlayer):\n",
        "    \"\"\"Visual Geometry Group's family of models\n",
        "    https://arxiv.org/abs/1409.1556\n",
        "    \"\"\"\n",
        "    if   nlayer == 11: return inference_vgg_impl(net, input_layer, [1,1,2,2,2]) # A\n",
        "    elif nlayer == 13: return inference_vgg_impl(net, input_layer, [2,2,2,2,2]) # B\n",
        "    elif nlayer == 16: return inference_vgg_impl(net, input_layer, [2,2,3,3,3]) # D\n",
        "    elif nlayer == 19: return inference_vgg_impl(net, input_layer, [2,2,4,4,4]) # E\n",
        "    else: raise ValueError(\"Invalid nlayer (%i); must be one of: 11,13,16,19\" %\n",
        "                           nlayer)\n",
        "\n",
        "def inference_googlenet(net, input_layer):\n",
        "    \"\"\"GoogLeNet model\n",
        "    https://arxiv.org/abs/1409.4842\n",
        "    \"\"\"\n",
        "    net.use_batch_norm = False\n",
        "    def inception_v1(net, x, k, l, m, n, p, q):\n",
        "        cols = [[('conv', k, (1,1))],\n",
        "                [('conv', l, (1,1)), ('conv', m, (3,3))],\n",
        "                [('conv', n, (1,1)), ('conv', p, (5,5))],\n",
        "                [('pool', 'MAX', (3,3), (1,1), 'SAME'), ('conv', q, (1,1))]]\n",
        "        return net.inception_module(x, 'incept_v1', cols)\n",
        "    x = net.input_layer(input_layer)\n",
        "    x = net.conv(x,    64, (7,7), (2,2))\n",
        "    x = net.pool(x, 'MAX', (3,3), padding='SAME')\n",
        "    x = net.conv(x,    64, (1,1))\n",
        "    x = net.conv(x,   192, (3,3))\n",
        "    x = net.pool(x, 'MAX', (3,3), padding='SAME')\n",
        "    x = inception_v1(net, x,  64,  96, 128, 16,  32,  32)\n",
        "    x = inception_v1(net, x, 128, 128, 192, 32,  96,  64)\n",
        "    x = net.pool(x, 'MAX', (3,3), padding='SAME')\n",
        "    x = inception_v1(net, x, 192,  96, 208, 16,  48,  64)\n",
        "    x = inception_v1(net, x, 160, 112, 224, 24,  64,  64)\n",
        "    x = inception_v1(net, x, 128, 128, 256, 24,  64,  64)\n",
        "    x = inception_v1(net, x, 112, 144, 288, 32,  64,  64)\n",
        "    x = inception_v1(net, x, 256, 160, 320, 32, 128, 128)\n",
        "    x = net.pool(x, 'MAX', (3,3), padding='SAME')\n",
        "    x = inception_v1(net, x, 256, 160, 320, 32, 128, 128)\n",
        "    x = inception_v1(net, x, 384, 192, 384, 48, 128, 128)\n",
        "    x = net.spatial_avg(x)\n",
        "    return x\n",
        "\n",
        "def inference_inception_v3(net, input_layer):\n",
        "    \"\"\"Google's Inception v3 model\n",
        "    https://arxiv.org/abs/1512.00567\n",
        "    \"\"\"\n",
        "    def inception_v3_a(net, x, n):\n",
        "        cols = [[('conv',  64, (1,1))],\n",
        "                [('conv',  48, (1,1)), ('conv',  64, (5,5))],\n",
        "                [('conv',  64, (1,1)), ('conv',  96, (3,3)), ('conv',  96, (3,3))],\n",
        "                [('pool', 'AVG', (3,3), (1,1), 'SAME'), ('conv',   n, (1,1))]]\n",
        "        return net.inception_module(x, 'incept_v3_a', cols)\n",
        "    def inception_v3_b(net, x):\n",
        "        cols = [[('conv',  64, (1,1)), ('conv',  96, (3,3)), ('conv',  96, (3,3), (2,2), 'VALID')],\n",
        "                [('conv', 384, (3,3), (2,2), 'VALID')],\n",
        "                [('pool', 'MAX', (3,3), (2,2), 'VALID')]]\n",
        "        return net.inception_module(x, 'incept_v3_b', cols)\n",
        "    def inception_v3_c(net, x, n):\n",
        "        cols = [[('conv', 192, (1,1))],\n",
        "                [('conv',   n, (1,1)), ('conv',   n, (1,7)), ('conv', 192, (7,1))],\n",
        "                [('conv',   n, (1,1)), ('conv',   n, (7,1)), ('conv',   n, (1,7)), ('conv',   n, (7,1)), ('conv', 192, (1,7))],\n",
        "                [('pool', 'AVG', (3,3), (1,1), 'SAME'), ('conv', 192, (1,1))]]\n",
        "        return net.inception_module(x, 'incept_v3_c', cols)\n",
        "    def inception_v3_d(net, x):\n",
        "        cols = [[('conv', 192, (1,1)), ('conv', 320, (3,3), (2,2), 'VALID')],\n",
        "                [('conv', 192, (1,1)), ('conv', 192, (1,7)), ('conv', 192, (7,1)), ('conv', 192, (3,3), (2,2), 'VALID')],\n",
        "                [('pool', 'MAX', (3,3), (2,2), 'VALID')]]\n",
        "        return net.inception_module(x, 'incept_v3_d',cols)\n",
        "    def inception_v3_e(net, x, pooltype):\n",
        "        cols = [[('conv', 320, (1,1))],\n",
        "                [('conv', 384, (1,1)), ('conv', 384, (1,3))],\n",
        "                [('share',),           ('conv', 384, (3,1))],\n",
        "                [('conv', 448, (1,1)), ('conv', 384, (3,3)), ('conv', 384, (1,3))],\n",
        "                [('share',),          ('share',),            ('conv', 384, (3,1))],\n",
        "                [('pool', pooltype, (3,3), (1,1), 'SAME'),   ('conv', 192, (1,1))]]\n",
        "        return net.inception_module(x, 'incept_v3_e', cols)\n",
        "\n",
        "    # TODO: This does not include the extra 'arm' that forks off\n",
        "    #         from before the 3rd-last module (the arm is designed\n",
        "    #         to speed up training in the early stages).\n",
        "    net.use_batch_norm = True\n",
        "    x = net.input_layer(input_layer)\n",
        "    x = net.conv(x,    32, (3,3), (2,2), padding='VALID')\n",
        "    x = net.conv(x,    32, (3,3), (1,1), padding='VALID')\n",
        "    x = net.conv(x,    64, (3,3), (1,1), padding='SAME')\n",
        "    x = net.pool(x, 'MAX', (3,3))\n",
        "    x = net.conv(x,    80, (1,1), (1,1), padding='VALID')\n",
        "    x = net.conv(x,   192, (3,3), (1,1), padding='VALID')\n",
        "    x = net.pool(x, 'MAX', (3,3))\n",
        "    x = inception_v3_a(net, x, 32)\n",
        "    x = inception_v3_a(net, x, 64)\n",
        "    x = inception_v3_a(net, x, 64)\n",
        "    x = inception_v3_b(net, x)\n",
        "    x = inception_v3_c(net, x, 128)\n",
        "    x = inception_v3_c(net, x, 160)\n",
        "    x = inception_v3_c(net, x, 160)\n",
        "    x = inception_v3_c(net, x, 192)\n",
        "    x = inception_v3_d(net, x)\n",
        "    x = inception_v3_e(net, x, 'AVG')\n",
        "    x = inception_v3_e(net, x, 'MAX')\n",
        "    x = net.spatial_avg(x)\n",
        "    return x\n",
        "\n",
        "def resnet_bottleneck_v1(net, input_layer, depth, depth_bottleneck, stride,\n",
        "                         basic=False):\n",
        "    num_inputs = input_layer.get_shape().as_list()[1]\n",
        "    x = input_layer\n",
        "    s = stride\n",
        "    with tf.name_scope('resnet_v1'):\n",
        "        if depth == num_inputs:\n",
        "            if stride == 1:\n",
        "                shortcut = input_layer\n",
        "            else:\n",
        "                shortcut = net.pool(x, 'MAX', (1,1), (s,s))\n",
        "        else:\n",
        "            shortcut = net.conv(x, depth, (1,1), (s,s), activation='LINEAR')\n",
        "        if basic:\n",
        "            x = net.conv(x, depth_bottleneck, (3,3), (s,s), padding='SAME_RESNET')\n",
        "            x = net.conv(x, depth,            (3,3), activation='LINEAR')\n",
        "        else:\n",
        "            x = net.conv(x, depth_bottleneck, (1,1), (s,s))\n",
        "            x = net.conv(x, depth_bottleneck, (3,3), padding='SAME')\n",
        "            x = net.conv(x, depth,            (1,1), activation='LINEAR')\n",
        "        x = net.activate(x + shortcut)\n",
        "        return x\n",
        "    \n",
        "def resnext_split_branch(net, input_layer, stride):\n",
        "    x = input_layer\n",
        "    with tf.name_scope('resnext_split_branch'):\n",
        "        x = net.conv(x, net.bottleneck_width, (1, 1), (stride, stride), activation='RELU', use_batch_norm=True)\n",
        "        x = net.conv(x, net.bottleneck_width, (3, 3), (1, 1), activation='RELU', use_batch_norm=True)\n",
        "    return x\n",
        "\n",
        "def resnext_shortcut(net, input_layer, stride, input_size, output_size):\n",
        "    x = input_layer\n",
        "    useConv = net.shortcut_type == 'C' or (net.shortcut_type == 'B' and input_size != output_size)\n",
        "    with tf.name_scope('resnext_shortcut'):\n",
        "        if useConv:\n",
        "            x = net.conv(x, output_size, (1,1), (stride, stride), use_batch_norm=True)\n",
        "        elif output_size == input_size:\n",
        "            if stride == 1:\n",
        "                x = input_layer\n",
        "            else:\n",
        "                x = net.pool(x, 'MAX', (1,1), (stride, stride))\n",
        "        else:\n",
        "            x = input_layer\n",
        "    return x\n",
        "\n",
        "def resnext_bottleneck_v1(net, input_layer, depth, depth_bottleneck, stride):\n",
        "    num_inputs = input_layer.get_shape().as_list()[1]\n",
        "    x = input_layer\n",
        "    with tf.name_scope('resnext_bottleneck_v1'):\n",
        "        shortcut = resnext_shortcut(net, x, stride, num_inputs, depth)\n",
        "        branches_list = []\n",
        "        for i in range(net.cardinality):\n",
        "            branch = resnext_split_branch(net, x, stride)\n",
        "            branches_list.append(branch)\n",
        "        concatenated_branches = tf.concat(values=branches_list, axis=1, name='concat')\n",
        "        bottleneck_depth = concatenated_branches.get_shape().as_list()[1]\n",
        "        x = net.conv(concatenated_branches, depth, (1, 1), (1, 1), activation=None)\n",
        "        x = net.activate(x + shortcut, 'RELU')\n",
        "    return x\n",
        "\n",
        "def inference_residual(net, input_layer, layer_counts, bottleneck_callback):\n",
        "    net.use_batch_norm = True\n",
        "    x = net.input_layer(input_layer)\n",
        "    x = net.conv(x, 64,    (7,7), (2,2), padding='SAME_RESNET')\n",
        "    x = net.pool(x, 'MAX', (3,3), (2,2), padding='SAME')\n",
        "    for i in range(layer_counts[0]):\n",
        "        x = bottleneck_callback(net, x,  256,  64, 1)\n",
        "    for i in range(layer_counts[1]):\n",
        "        x = bottleneck_callback(net, x, 512, 128, 2 if i==0 else 1)\n",
        "    for i in range(layer_counts[2]):\n",
        "        x = bottleneck_callback(net, x, 1024, 256, 2 if i==0 else 1)\n",
        "    for i in range(layer_counts[3]):\n",
        "        x = bottleneck_callback(net, x, 2048, 512, 2 if i==0 else 1)\n",
        "    x = net.spatial_avg(x)\n",
        "    return x\n",
        "\n",
        "def inference_resnet_v1_basic_impl(net, input_layer, layer_counts):\n",
        "    basic_resnet_bottleneck_callback = partial(resnet_bottleneck_v1, basic=True)\n",
        "    return inference_residual(net, input_layer, layer_counts, basic_resnet_bottleneck_callback)\n",
        "\n",
        "def inference_resnet_v1_impl(net, input_layer, layer_counts):\n",
        "    return inference_residual(net, input_layer, layer_counts, resnet_bottleneck_v1)\n",
        "\n",
        "def inference_resnext_v1_impl(net, input_layer, layer_counts):\n",
        "    return inference_residual(net, input_layer, layer_counts, resnext_bottleneck_v1)\n",
        "\n",
        "def inference_resnet_v1(net, input_layer, nlayer):\n",
        "    \"\"\"Deep Residual Networks family of models\n",
        "    https://arxiv.org/abs/1512.03385\n",
        "    \"\"\"\n",
        "    if   nlayer ==  18: return inference_resnet_v1_basic_impl(net, input_layer, [2,2, 2,2])\n",
        "    elif nlayer ==  34: return inference_resnet_v1_basic_impl(net, input_layer, [3,4, 6,3])\n",
        "    elif nlayer ==  50: return inference_resnet_v1_impl(net, input_layer, [3,4, 6,3])\n",
        "    elif nlayer == 101: return inference_resnet_v1_impl(net, input_layer, [3,4,23,3])\n",
        "    elif nlayer == 152: return inference_resnet_v1_impl(net, input_layer, [3,8,36,3])\n",
        "    else: raise ValueError(\"Invalid nlayer (%i); must be one of: 18,34,50,101,152\" %\n",
        "                           nlayer)\n",
        "        \n",
        "def inference_resnext_v1(net, input_layer, nlayer):\n",
        "    \"\"\"Aggregated  Residual Networks family of models\n",
        "    https://arxiv.org/abs/1611.05431\n",
        "    \"\"\"\n",
        "    cardinality_to_bottleneck_width = { 1:64, 2:40, 4:24, 8:14, 32:4 }\n",
        "    net.cardinality = 32\n",
        "    net.shortcut_type = 'B'\n",
        "    assert net.cardinality in cardinality_to_bottleneck_width.keys(), \\\n",
        "    \"Invalid  cardinality (%i); must be one of: 1,2,4,8,32\" % net.cardinality\n",
        "    net.bottleneck_width = cardinality_to_bottleneck_width[net.cardinality]  \n",
        "    if nlayer ==  50: return inference_resnext_v1_impl(net, input_layer, [3,4, 6,3])\n",
        "    elif nlayer == 101: return inference_resnext_v1_impl(net, input_layer, [3,4,23,3])\n",
        "    elif nlayer == 152: return inference_resnext_v1_impl(net, input_layer, [3,8,36,3])\n",
        "    else: raise ValueError(\"Invalid nlayer (%i); must be one of: 50,101,152\" %\n",
        "                           nlayer)\n",
        "\n",
        "# Stem functions\n",
        "def inception_v4_sa(net, x):\n",
        "    cols = [[('pool', 'MAX', (3,3))],\n",
        "            [('conv',  96, (3,3), (2,2), 'VALID')]]\n",
        "    return net.inception_module(x, 'incept_v4_sa', cols)\n",
        "def inception_v4_sb(net, x):\n",
        "    cols = [[('conv',  64, (1,1)), ('conv',  96, (3,3), (1,1), 'VALID')],\n",
        "            [('conv',  64, (1,1)), ('conv',  64, (7,1)), ('conv',  64, (1,7)), ('conv',  96, (3,3), (1,1), 'VALID')]]\n",
        "    return net.inception_module(x, 'incept_v4_sb', cols)\n",
        "def inception_v4_sc(net, x):\n",
        "    cols = [[('conv', 192, (3,3), (2,2), 'VALID')],\n",
        "            [('pool', 'MAX', (3,3))]]\n",
        "    return net.inception_module(x, 'incept_v4_sc', cols)\n",
        "# Reduction functions\n",
        "def inception_v4_ra(net, x, k, l, m, n):\n",
        "    cols = [[('pool', 'MAX', (3,3))],\n",
        "            [('conv',   n, (3,3), (2,2), 'VALID')],\n",
        "            [('conv',   k, (1,1)), ('conv',   l, (3,3)), ('conv',   m, (3,3), (2,2), 'VALID')]]\n",
        "    return net.inception_module(x, 'incept_v4_ra', cols)\n",
        "def inception_v4_rb(net, x):\n",
        "    cols = [[('pool', 'MAX', (3,3))],\n",
        "            [('conv', 192, (1,1)), ('conv', 192, (3,3), (2,2), 'VALID')],\n",
        "            [('conv', 256, (1,1)), ('conv', 256, (1,7)), ('conv', 320, (7,1)), ('conv', 320, (3,3), (2,2), 'VALID')]]\n",
        "    return net.inception_module(x, 'incept_v4_rb', cols)\n",
        "def inception_resnet_v2_rb(net, x):\n",
        "    cols = [[('pool', 'MAX', (3,3))],\n",
        "            # Note: These match Facebook's Torch implem\n",
        "            [('conv', 256, (1,1)), ('conv', 384, (3,3), (2,2), 'VALID')],\n",
        "            [('conv', 256, (1,1)), ('conv', 256, (3,3), (2,2), 'VALID')],\n",
        "            [('conv', 256, (1,1)), ('conv', 256, (3,3)), ('conv', 256, (3,3), (2,2), 'VALID')]]\n",
        "    return net.inception_module(x, 'incept_resnet_v2_rb', cols)\n",
        "\n",
        "def inference_inception_v4(net, input_layer):\n",
        "    \"\"\"Google's Inception v4 model\n",
        "    https://arxiv.org/abs/1602.07261\n",
        "    \"\"\"\n",
        "    def inception_v4_a(net, x):\n",
        "        cols = [[('pool', 'AVG', (3,3), (1,1), 'SAME'), ('conv',  96, (1,1))],\n",
        "                [('conv',  96, (1,1))],\n",
        "                [('conv',  64, (1,1)), ('conv',  96, (3,3))],\n",
        "                [('conv',  64, (1,1)), ('conv',  96, (3,3)), ('conv',  96, (3,3))]]\n",
        "        return net.inception_module(x, 'incept_v4_a', cols)\n",
        "    def inception_v4_b(net, x):\n",
        "        cols = [[('pool', 'AVG', (3,3), (1,1), 'SAME'), ('conv', 128, (1,1))],\n",
        "                [('conv', 384, (1,1))],\n",
        "                [('conv', 192, (1,1)), ('conv', 224, (1,7)), ('conv', 256, (7,1))],\n",
        "                [('conv', 192, (1,1)), ('conv', 192, (1,7)), ('conv', 224, (7,1)), ('conv', 224, (1,7)), ('conv', 256, (7,1))]]\n",
        "        return net.inception_module(x, 'incept_v4_b', cols)\n",
        "    def inception_v4_c(net, x):\n",
        "        cols = [[('pool', 'AVG', (3,3), (1,1), 'SAME'), ('conv', 256, (1,1))],\n",
        "                [('conv', 256, (1,1))],\n",
        "                [('conv', 384, (1,1)), ('conv', 256, (1,3))],\n",
        "                [('share',),           ('conv', 256, (3,1))],\n",
        "                [('conv', 384, (1,1)), ('conv', 448, (1,3)), ('conv', 512, (3,1)), ('conv', 256, (3,1))],\n",
        "                [('share',),           ('share',),           ('share',),           ('conv', 256, (1,3))]]\n",
        "        return net.inception_module(x, 'incept_v4_c', cols)\n",
        "\n",
        "    net.use_batch_norm = True\n",
        "    x = net.input_layer(input_layer)\n",
        "    x = net.conv(x, 32, (3,3), (2,2), padding='VALID')\n",
        "    x = net.conv(x, 32, (3,3), (1,1), padding='VALID')\n",
        "    x = net.conv(x, 64, (3,3))\n",
        "    x = inception_v4_sa(net, x)\n",
        "    x = inception_v4_sb(net, x)\n",
        "    x = inception_v4_sc(net, x)\n",
        "    for _ in range(4):\n",
        "        x = inception_v4_a(net, x)\n",
        "    x = inception_v4_ra(net, x, 192, 224, 256, 384)\n",
        "    for _ in range(7):\n",
        "        x = inception_v4_b(net, x)\n",
        "    x = inception_v4_rb(net, x)\n",
        "    for _ in range(3):\n",
        "        x = inception_v4_c(net, x)\n",
        "    x = net.spatial_avg(x)\n",
        "    x = net.dropout(x, 0.8)\n",
        "    return x\n",
        "\n",
        "def inference_inception_resnet_v2(net, input_layer):\n",
        "    \"\"\"Google's Inception-Resnet v2 model\n",
        "    https://arxiv.org/abs/1602.07261\n",
        "    \"\"\"\n",
        "    def inception_resnet_v2_a(net, x):\n",
        "        cols = [[('conv',  32, (1,1))],\n",
        "                [('conv',  32, (1,1)), ('conv',  32, (3,3))],\n",
        "                [('conv',  32, (1,1)), ('conv',  48, (3,3)), ('conv',  64, (3,3))]]\n",
        "        x = net.inception_module(x, 'incept_resnet_v2_a', cols)\n",
        "        x = net.conv(x, 384, (1,1), activation='LINEAR')\n",
        "        return x\n",
        "    def inception_resnet_v2_b(net, x):\n",
        "        cols = [[('conv', 192, (1,1))],\n",
        "                [('conv', 128, (1,1)), ('conv', 160, (1,7)), ('conv', 192, (7,1))]]\n",
        "        x = net.inception_module(x, 'incept_resnet_v2_b', cols)\n",
        "        x = net.conv(x, 1152, (1,1), activation='LINEAR')\n",
        "        return x\n",
        "    def inception_resnet_v2_c(net, x):\n",
        "        cols = [[('conv', 192, (1,1))],\n",
        "                [('conv', 192, (1,1)), ('conv', 224, (1,3)), ('conv', 256, (3,1))]]\n",
        "        x = net.inception_module(x, 'incept_resnet_v2_c', cols)\n",
        "        x = net.conv(x, 2048, (1,1), activation='LINEAR')\n",
        "        return x\n",
        "\n",
        "    net.use_batch_norm = True\n",
        "    residual_scale = 0.2\n",
        "    x = net.input_layer(input_layer)\n",
        "    x = net.conv(x, 32, (3,3), (2,2), padding='VALID')\n",
        "    x = net.conv(x, 32, (3,3), (1,1), padding='VALID')\n",
        "    x = net.conv(x, 64, (3,3))\n",
        "    x = inception_v4_sa(net, x)\n",
        "    x = inception_v4_sb(net, x)\n",
        "    x = inception_v4_sc(net, x)\n",
        "    for _ in range(5):\n",
        "        x = net.residual(x, inception_resnet_v2_a, scale=residual_scale)\n",
        "    x = inception_v4_ra(net, x, 256, 256, 384, 384)\n",
        "    for _ in range(10):\n",
        "        x = net.residual(x, inception_resnet_v2_b, scale=residual_scale)\n",
        "    x = inception_resnet_v2_rb(net, x)\n",
        "    for _ in range(5):\n",
        "        x = net.residual(x, inception_resnet_v2_c, scale=residual_scale)\n",
        "    x = net.spatial_avg(x)\n",
        "    x = net.dropout(x, 0.8)\n",
        "    return x\n",
        "\n",
        "def run_evaluation(nstep, sess, top1_op, top5_op, enqueue_ops):\n",
        "    print(\"Evaluating\")\n",
        "    top1s = []\n",
        "    top5s = []\n",
        "    print(\"  Step  Top-1  Top-5\")\n",
        "    for step in range(nstep):\n",
        "        try:\n",
        "            top1, top5 = sess.run([top1_op, top5_op, enqueue_ops])[:2]\n",
        "            if step == 0 or (step+1) % FLAGS.display_every == 0:\n",
        "                print(\"% 6i %5.1f%% %5.1f%%\" % (step+1, top1*100, top5*100))\n",
        "            top1s.append(top1)\n",
        "            top5s.append(top5)\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"Keyboard interrupt\")\n",
        "            break\n",
        "    nstep = len(top1s)\n",
        "    if nstep == 0:\n",
        "        return\n",
        "    top1s = np.asarray(top1s) * 100.\n",
        "    top5s = np.asarray(top5s) * 100.\n",
        "    top1_mean = np.mean(top1s)\n",
        "    top5_mean = np.mean(top5s)\n",
        "    if nstep > 2:\n",
        "        top1_uncertainty = np.std(top1s, ddof=1) / np.sqrt(float(nstep))\n",
        "        top5_uncertainty = np.std(top5s, ddof=1) / np.sqrt(float(nstep))\n",
        "    else:\n",
        "        top1_uncertainty = float('nan')\n",
        "        top5_uncertainty = float('nan')\n",
        "    top1_madstd = 1.4826*np.median(np.abs(top1s - np.median(top1s)))\n",
        "    top5_madstd = 1.4826*np.median(np.abs(top5s - np.median(top5s)))\n",
        "    print('-' * 64)\n",
        "    print('Validation Top-1: %.3f %% +/- %.2f (jitter = %.1f)' % (\n",
        "        top1_mean, top1_uncertainty, top1_madstd))\n",
        "    print('Validation Top-5: %.3f %% +/- %.2f (jitter = %.1f)' % (\n",
        "        top5_mean, top5_uncertainty, top5_madstd))\n",
        "    print('-' * 64)\n",
        "\n",
        "def get_num_records(tf_record_pattern):\n",
        "    def count_records(tf_record_filename):\n",
        "        count = 0\n",
        "        for _ in tf.python_io.tf_record_iterator(tf_record_filename):\n",
        "            count += 1\n",
        "        return count\n",
        "    filenames = sorted(tf.gfile.Glob(tf_record_pattern))\n",
        "    nfile = len(filenames)\n",
        "    return (count_records(filenames[0])*(nfile-1) +\n",
        "            count_records(filenames[-1]))\n",
        "\n",
        "def add_bool_argument(cmdline, shortname, longname=None, default=False, help=None):\n",
        "    if longname is None:\n",
        "        shortname, longname = None, shortname\n",
        "    elif default == True:\n",
        "        raise ValueError(\"\"\"Boolean arguments that are True by default should not have short names.\"\"\")\n",
        "    name = longname[2:]\n",
        "    feature_parser = cmdline.add_mutually_exclusive_group(required=False)\n",
        "    if shortname is not None:\n",
        "        feature_parser.add_argument(shortname, '--'+name, dest=name, action='store_true', help=help, default=default)\n",
        "    else:\n",
        "        feature_parser.add_argument(           '--'+name, dest=name, action='store_true', help=help, default=default)\n",
        "    feature_parser.add_argument('--no'+name, dest=name, action='store_false')\n",
        "    return cmdline\n",
        "\n",
        "def main():\n",
        "    global_start_time = time.time()\n",
        "    tf.set_random_seed(1234+hvd.rank())\n",
        "    np.random.seed(4321+hvd.rank())\n",
        "    cmdline = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "    # Basic options\n",
        "    cmdline.add_argument('-m', '--model', required=True,\n",
        "                         help=\"\"\"Name of model to run:\n",
        "                         trivial, lenet,\n",
        "                         alexnet, googlenet, vgg[11,13,16,19],\n",
        "                         inception[3,4], resnet[18,34,50,101,152],\n",
        "                         resnext[50,101,152], inception-resnet2.\"\"\")\n",
        "    cmdline.add_argument('--data_dir', default=None,\n",
        "                         help=\"\"\"Path to dataset in TFRecord format\n",
        "                         (aka Example protobufs). Files should be\n",
        "                         named 'train-*' and 'validation-*'.\"\"\")\n",
        "    cmdline.add_argument('-b', '--batch_size', default=64, type=int,\n",
        "                         help=\"\"\"Size of each minibatch.\"\"\")\n",
        "    cmdline.add_argument('--num_batches', default=50, type=int,\n",
        "                         help=\"\"\"Number of batches to run.\n",
        "                         Ignored during eval.\"\"\")\n",
        "    cmdline.add_argument('--num_epochs', default=None, type=int,\n",
        "                         help=\"\"\"Number of epochs to run.\n",
        "                         Overrides --num_batches. Ignored during eval.\"\"\")\n",
        "    cmdline.add_argument('--log_dir', default=\"\",\n",
        "                         help=\"\"\"Directory in which to write training\n",
        "                         summaries and checkpoints.\"\"\")\n",
        "    cmdline.add_argument('--display_every', default=1, type=int,\n",
        "                         help=\"\"\"How often (in iterations) to print out\n",
        "                         running information.\"\"\")\n",
        "    cmdline.add_argument('--save_interval', default=43200, type=int,\n",
        "                         help=\"\"\"Time in seconds between checkpoints.\"\"\")\n",
        "    cmdline.add_argument('--summary_interval', default=3600, type=int,\n",
        "                         help=\"\"\"Time in seconds between saves of summary statistics.\"\"\")\n",
        "    add_bool_argument(cmdline, '--eval',\n",
        "                      help=\"\"\"Evaluate the top-1 and top-5 accuracy of\n",
        "                      a checkpointed model.\"\"\")\n",
        "    add_bool_argument(cmdline, '--fp16',\n",
        "                      help=\"\"\"Train using float16 (half) precision instead\n",
        "                      of float32.\"\"\")\n",
        "\n",
        "    global FLAGS\n",
        "    FLAGS, unknown_args = cmdline.parse_known_args()\n",
        "    if len(unknown_args) > 0:\n",
        "        for bad_arg in unknown_args:\n",
        "            print(\"ERROR: Unknown command line arg: %s\" % bad_arg)\n",
        "        raise ValueError(\"Invalid command line arg(s)\")\n",
        "\n",
        "    if not os.path.exists(FLAGS.log_dir):\n",
        "        os.makedirs(FLAGS.log_dir)\n",
        "\n",
        "    # create logger with 'aws-tf-cnn'\n",
        "    logger = logging.getLogger('aws-tf-hvd-cnn')\n",
        "    logger.setLevel(logging.DEBUG)  # INFO, ERROR\n",
        "    # file handler which logs debug messages\n",
        "    fh = logging.FileHandler(os.path.join(FLAGS.log_dir, 'aws-tf-hvd-cnn.log'))\n",
        "    fh.setLevel(logging.DEBUG)\n",
        "    # console handler\n",
        "    ch = logging.StreamHandler()\n",
        "    ch.setLevel(logging.INFO)\n",
        "    # add formatter to the handlers\n",
        "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "    fh.setFormatter(formatter)\n",
        "    ch.setFormatter(formatter)\n",
        "    # add handlers to logger\n",
        "    logger.addHandler(fh)\n",
        "    logger.addHandler(ch)\n",
        "\n",
        "    nclass = 1000\n",
        "    batch_size = FLAGS.batch_size\n",
        "    subset = 'validation' if FLAGS.eval else 'train'\n",
        "\n",
        "    tfversion = tensorflow_version_tuple()\n",
        "    logger.info(\"TensorFlow:  %i.%i.%s\" % tfversion)\n",
        "    logger.info(\"This script: {} v{}\".format(__file__, __version__))\n",
        "    logger.info(\"Parameters specified:\")\n",
        "    logger.info('\\n'.join(['  '+arg for arg in sys.argv[1:]]))\n",
        "\n",
        "    if FLAGS.data_dir is not None and FLAGS.data_dir != '':\n",
        "        nrecord = get_num_records(os.path.join(FLAGS.data_dir, '%s-*' % subset))\n",
        "    else:\n",
        "        nrecord = FLAGS.num_batches * batch_size * hvd.size()\n",
        "\n",
        "    # Training hyperparameters\n",
        "    FLAGS.learning_rate         = 0.001 # Model-specific values are set below\n",
        "    FLAGS.momentum              = 0.9\n",
        "    FLAGS.lr_decay_policy       = 'piecewise' #'poly'\n",
        "    FLAGS.lr_decay_epochs       = 30\n",
        "    FLAGS.lr_decay_rate         = 0.1\n",
        "    FLAGS.lr_poly_power         = 2.\n",
        "    FLAGS.weight_decay          = 1e-4\n",
        "    FLAGS.input_buffer_size     = min(10000, nrecord)\n",
        "    FLAGS.distort_color         = False\n",
        "    FLAGS.nstep_burnin          = 20\n",
        "    FLAGS.loss_scale            = 256. # TODO: May need to decide this based on model\n",
        "    FLAGS.LARC_eta              = None #0.003\n",
        "    FLAGS.LARC_epsilon          = 1.\n",
        "    FLAGS.LARC_mode             = 'clip'\n",
        "    FLAGS.sync_period           = 8\n",
        "\n",
        "    model_dtype = tf.float16 if FLAGS.fp16 else tf.float32\n",
        "\n",
        "    logger.info(\"Num ranks:  {}\".format(hvd.size()))\n",
        "    logger.info(\"Num of images: {}\".format(nrecord)) if FLAGS.data_dir is not None else logger.info('Synthetic')\n",
        "    logger.info(\"Model: {}\".format(FLAGS.model))\n",
        "    logger.info(\"Total batch size: {}\".format(batch_size * hvd.size()))\n",
        "    logger.info(\"{}, per device\".format(batch_size))\n",
        "    logger.info(\"Data format: 'NCHW'\")\n",
        "    logger.info(\"Data type:  fp16\") if model_dtype == tf.float16 else logger.info('Data type:  fp32')\n",
        "\n",
        "    if FLAGS.num_epochs is not None:\n",
        "        if FLAGS.data_dir is None:\n",
        "            logger.error(\"num_epochs requires data_dir to be specified\")\n",
        "            raise ValueError(\"num_epochs requires data_dir to be specified\")\n",
        "        nstep = nrecord * FLAGS.num_epochs // (batch_size * hvd.size())\n",
        "    else:\n",
        "        nstep = FLAGS.num_batches\n",
        "        FLAGS.num_epochs = max(nstep * batch_size * hvd.size() // nrecord, 1)\n",
        "\n",
        "    model_name = FLAGS.model\n",
        "    if   model_name == 'trivial':\n",
        "        height, width = 224, 224\n",
        "        model_func = inference_trivial\n",
        "    elif model_name == 'lenet':\n",
        "        height, width = 28, 28\n",
        "        model_func = inference_lenet5\n",
        "    elif model_name == 'alexnet':\n",
        "        height, width = 227, 227\n",
        "        model_func = inference_alexnet_owt\n",
        "        FLAGS.learning_rate = 0.03\n",
        "    elif model_name == 'overfeat':\n",
        "        height, width = 231, 231\n",
        "        model_func = inference_overfeat\n",
        "    elif model_name.startswith('vgg'):\n",
        "        height, width = 224, 224\n",
        "        nlayer = int(model_name[len('vgg'):])\n",
        "        model_func = lambda net, images: inference_vgg(net, images, nlayer)\n",
        "        FLAGS.learning_rate = 0.02\n",
        "    elif model_name == 'googlenet':\n",
        "        height, width = 224, 224\n",
        "        model_func = inference_googlenet\n",
        "        FLAGS.learning_rate = 0.04\n",
        "    elif model_name == 'inception3':\n",
        "        height, width = 299, 299\n",
        "        model_func = inference_inception_v3\n",
        "        FLAGS.learning_rate = 0.2\n",
        "    elif model_name.startswith('resnet'):\n",
        "        height, width = 224, 224\n",
        "        nlayer = int(model_name[len('resnet'):])\n",
        "        model_func = lambda net, images: inference_resnet_v1(net, images, nlayer)\n",
        "        FLAGS.learning_rate = 1. * (batch_size * hvd.size() / 1024.0) if nlayer > 18 else 0.5\n",
        "    elif model_name.startswith('resnext'):\n",
        "        height, width = 224, 224\n",
        "        nlayer = int(model_name[len('resnext'):])\n",
        "        model_func = lambda net, images: inference_resnext_v1(net, images, nlayer)\n",
        "        FLAGS.learning_rate = 0.1\n",
        "    elif model_name == 'inception4':\n",
        "        height, width = 299, 299\n",
        "        model_func = inference_inception_v4\n",
        "        FLAGS.learning_rate = 0.045\n",
        "    elif model_name == 'inception-resnet2':\n",
        "        height, width = 299, 299\n",
        "        model_func = inference_inception_resnet_v2\n",
        "        FLAGS.learning_rate = 0.045\n",
        "    else:\n",
        "        logger.error(\"Invalid model type: {}\".format(model_name))\n",
        "        raise ValueError(\"Invalid model type: %s\" % model_name)\n",
        "\n",
        "    if FLAGS.data_dir is None:\n",
        "        preprocessor = DummyPreprocessor(height, width, batch_size, nclass)\n",
        "    else:\n",
        "        preprocessor = ImagePreprocessor(height, width, subset)\n",
        "\n",
        "    def loss_func(images, labels, var_scope):\n",
        "        # Build the forward model\n",
        "        net = GPUNetworkBuilder(True, dtype=model_dtype)\n",
        "        output = model_func(net, images)\n",
        "        # Add final FC layer to produce nclass outputs\n",
        "        logits = net.fully_connected(output, nclass, activation='LINEAR')\n",
        "        if logits.dtype != tf.float32:\n",
        "            logits = tf.cast(logits, tf.float32)\n",
        "        loss = tf.losses.sparse_softmax_cross_entropy(\n",
        "            logits=logits, labels=labels)\n",
        "        # Add weight decay\n",
        "        if FLAGS.weight_decay is not None and FLAGS.weight_decay != 0.:\n",
        "            params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
        "                                       scope=var_scope.name)\n",
        "            l2_loss = tf.add_n([tf.nn.l2_loss(w) for w in params])\n",
        "            if l2_loss.dtype != tf.float32:\n",
        "                l2_loss = tf.cast(l2_loss, tf.float32)\n",
        "            loss += FLAGS.weight_decay * l2_loss\n",
        "        return loss, logits\n",
        "    def eval_func(images, labels, var_scope):\n",
        "        net = GPUNetworkBuilder(False, dtype=model_dtype)\n",
        "        output = model_func(net, images)\n",
        "        logits = net.fully_connected(output, nclass, activation='LINEAR')\n",
        "        if logits.dtype != tf.float32:\n",
        "            logits = tf.cast(logits, tf.float32)\n",
        "        with tf.device('/cpu:0'):\n",
        "            top1 = tf.reduce_mean(\n",
        "                tf.cast(tf.nn.in_top_k(logits, labels, 1), tf.float32))\n",
        "            top5 = tf.reduce_mean(\n",
        "                tf.cast(tf.nn.in_top_k(logits, labels, 5), tf.float32))\n",
        "        return top1, top5\n",
        "\n",
        "    if FLAGS.eval:\n",
        "        if FLAGS.data_dir is None:\n",
        "            logger.error(\"eval requires data_dir to be specified\")\n",
        "            raise ValueError(\"eval requires data_dir to be specified\")\n",
        "        if FLAGS.fp16:\n",
        "            logger.error(\"eval cannot be run with in fp16\")\n",
        "            raise ValueError(\"eval cannot be run with in fp16\")\n",
        "        if hvd.size() > 1:\n",
        "            logger.error(\"Multi-GPU evaluation is not supported\")\n",
        "            raise ValueError(\"Multi-GPU evaluation is not supported\")\n",
        "        evaluator = FeedForwardEvaluator(preprocessor, eval_func)\n",
        "        logger.info(\"Building evaluation graph\")\n",
        "        top1_op, top5_op, enqueue_ops = evaluator.evaluation_step(batch_size)\n",
        "    else:\n",
        "        sync_weights = tf.placeholder(dtype=tf.bool, name='sync_weights')\n",
        "        wipe_memory = tf.placeholder(dtype=tf.bool, name='wipe_memory')\n",
        "        nstep_per_epoch = nrecord // (batch_size * hvd.size())\n",
        "        trainer = FeedForwardTrainer(preprocessor, loss_func, nstep_per_epoch, FLAGS.sync_period)\n",
        "        logger.info(\"Building training graph\")\n",
        "        total_loss, learning_rate, train_ops = trainer.training_step(\n",
        "            batch_size, sync_weights, wipe_memory)\n",
        "\n",
        "    logger.info(\"Creating session\")\n",
        "    config = tf.ConfigProto(allow_soft_placement = True)\n",
        "    config.intra_op_parallelism_threads = 1\n",
        "    config.inter_op_parallelism_threads = 10\n",
        "    config.gpu_options.force_gpu_compatible = True\n",
        "    config.gpu_options.visible_device_list = str(hvd.local_rank())\n",
        "\n",
        "    sess = tf.Session(config=config)\n",
        "\n",
        "    train_writer = None\n",
        "    saver = None\n",
        "    summary_ops = None\n",
        "    if hvd.rank() == 0 and len(FLAGS.log_dir):\n",
        "        log_dir = FLAGS.log_dir\n",
        "        train_writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
        "        summary_ops = tf.summary.merge_all()\n",
        "        last_summary_time = time.time()\n",
        "        saver = tf.train.Saver(max_to_keep=None)\n",
        "        last_save_time = time.time()\n",
        "\n",
        "    if not FLAGS.eval:\n",
        "        logger.info(\"Initializing variables\")\n",
        "        trainer.init(sess)\n",
        "\n",
        "    restored = False\n",
        "    if hvd.rank() == 0 and saver is not None:\n",
        "        ckpt = tf.train.get_checkpoint_state(FLAGS.log_dir)\n",
        "        checkpoint_file = os.path.join(FLAGS.log_dir, \"checkpoint\")\n",
        "        if ckpt and ckpt.model_checkpoint_path:\n",
        "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "            restored = True\n",
        "            logger.info(\"Restored session from checkpoint {}\".format(ckpt.model_checkpoint_path))\n",
        "        else:\n",
        "            if not os.path.exists(FLAGS.log_dir):\n",
        "                os.mkdir(FLAGS.log_dir)\n",
        "\n",
        "    if FLAGS.eval:\n",
        "        if not restored:\n",
        "            logger.error(\"No checkpoint found for evaluation\")\n",
        "            raise ValueError(\"No checkpoint found for evaluation\")\n",
        "        else:\n",
        "            logger.info(\"Pre-filling input pipeline\")\n",
        "            evaluator.prefill_pipeline(sess)\n",
        "            nstep = nrecord // batch_size\n",
        "            run_evaluation(nstep, sess, top1_op, top5_op, enqueue_ops)\n",
        "            return\n",
        "\n",
        "    trainer.sync(sess)\n",
        "\n",
        "    if hvd.rank() == 0 and not restored:\n",
        "        if saver is not None:\n",
        "            save_path = saver.save(sess, checkpoint_file, global_step=0)\n",
        "            print(\"Checkpoint written to\", save_path)\n",
        "\n",
        "    logger.info(\"Pre-filling input pipeline\")\n",
        "    trainer.prefill_pipeline(sess)\n",
        "    logger.info(\"Writing summaries to {}\".format(FLAGS.log_dir))\n",
        "    logger.info(\"Training\")\n",
        "    logger.info(\"  Step Epoch Img/sec   Loss   LR\")\n",
        "    batch_times = []\n",
        "    oom = False\n",
        "    step0 = int(sess.run(trainer.global_step))\n",
        "\n",
        "    all_stats = []\n",
        "\n",
        "    for step in range(step0, nstep):\n",
        "        ops_to_run = [total_loss, learning_rate] + train_ops\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            run_options = tf.RunOptions(trace_level=tf.RunOptions.NO_TRACE)\n",
        "            run_metadata = tf.RunMetadata()\n",
        "            if (hvd.rank() == 0 and summary_ops is not None and\n",
        "                (step == 0 or step+1 == nstep or\n",
        "                 time.time() - last_summary_time > FLAGS.summary_interval)):\n",
        "                if step != 0:\n",
        "                    last_summary_time += FLAGS.summary_interval\n",
        "                summary, loss, lr = sess.run([summary_ops] + ops_to_run, options=run_options, run_metadata=run_metadata, feed_dict={sync_weights: (step%FLAGS.sync_period == 0), wipe_memory: False})[:3]\n",
        "                train_writer.add_summary(summary, step)\n",
        "            else:\n",
        "                loss, lr = sess.run(ops_to_run, options=run_options, run_metadata=run_metadata, feed_dict={sync_weights: (step%FLAGS.sync_period == 0), wipe_memory: (step in trainer.boundaries)})[:2]\n",
        "            elapsed = time.time() - start_time\n",
        "            all_stats.append(run_metadata.step_stats)\n",
        "        except KeyboardInterrupt:\n",
        "            logger.info(\"Keyboard interrupt\")\n",
        "            break\n",
        "        except tf.errors.ResourceExhaustedError:\n",
        "            elapsed = -1.\n",
        "            loss    = 0.\n",
        "            lr      = -1\n",
        "            oom = True\n",
        "\n",
        "        if (hvd.rank() == 0 and saver is not None and\n",
        "            (time.time() - last_save_time > FLAGS.save_interval or step+1 == nstep)):\n",
        "            last_save_time += FLAGS.save_interval\n",
        "            save_path = saver.save(sess, checkpoint_file,\n",
        "                                   global_step=trainer.global_step)\n",
        "            print(\"Checkpoint written to\", save_path)\n",
        "\n",
        "        if step >= FLAGS.nstep_burnin:\n",
        "            batch_times.append(elapsed)\n",
        "        img_per_sec = batch_size / elapsed\n",
        "        effective_accuracy = 100. / math.exp(min(loss,20.))\n",
        "        if step == 0 or (step+1) % FLAGS.display_every == 0:\n",
        "            epoch = step*batch_size*hvd.size() // nrecord\n",
        "            logger.info(\"%6i %5i %7.1f %7.3f %7.5f\" % (\n",
        "                step+1, epoch+1, img_per_sec*hvd.size(), loss, lr))\n",
        "        if oom:\n",
        "            break\n",
        "\n",
        "    nstep = len(batch_times)\n",
        "    if nstep > 0:\n",
        "        batch_times = np.array(batch_times)\n",
        "        speeds = batch_size*hvd.size() / batch_times\n",
        "        speed_mean = np.mean(speeds)\n",
        "        if nstep > 2:\n",
        "            speed_uncertainty = np.std(speeds, ddof=1) / np.sqrt(float(nstep))\n",
        "        else:\n",
        "            speed_uncertainty = float('nan')\n",
        "        speed_madstd = 1.4826*np.median(np.abs(speeds - np.median(speeds)))\n",
        "        speed_jitter = speed_madstd\n",
        "        logger.info('-' * 64)\n",
        "        logger.info('Images/sec: %.1f +/- %.1f (jitter = %.1f)' % (\n",
        "            speed_mean, speed_uncertainty, speed_jitter))\n",
        "        logger.info('-' * 64)\n",
        "    else:\n",
        "        logger.info(\"No results, did not get past burn-in phase (%i steps)\" %\n",
        "              FLAGS.nstep_burnin)\n",
        "\n",
        "    if train_writer is not None:\n",
        "        train_writer.close()\n",
        "\n",
        "    global_end_time = time.time()\n",
        "    #logger.info(\"start time is {}, end time is {}\".format(global_start_time, global_end_time))\n",
        "    logger.info('Time used in total: %.1f seconds' % (global_end_time - global_start_time))\n",
        "\n",
        "    if oom:\n",
        "        print(\"Out of memory error detected, exiting\")\n",
        "        sys.exit(-2)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "4kDVbU7pemb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "eval_resnet.py"
      ],
      "metadata": {
        "id": "4ycwrRijeplr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2XdUTEadmI8"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"\n",
        "Changelog:\n",
        "1.2\n",
        "  - Add logging to file and console\n",
        "1.1\n",
        "  - Center crop evaluation images\n",
        "  - Enable LARC learning rate control\n",
        "  - Correctly order UPDATE_OPS and global_step update during training.\n",
        "  - Set default learning rate policy to polynomial decay.\n",
        "  - Add cmd line options for checkpoint and summary intervals.\n",
        "  - Add loss scaling.\n",
        "  - Scale resnet learning rate by batch size.\n",
        "1.0\n",
        "  - Initial version\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "from builtins import range\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.ops import data_flow_ops\n",
        "from tensorflow.python.ops import init_ops\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import logging\n",
        "from collections import defaultdict\n",
        "import argparse\n",
        "\n",
        "import pickle\n",
        "\n",
        "try:\n",
        "    import horovod.tensorflow as hvd\n",
        "except:\n",
        "    print(\"Failed to import horovod module. \"\n",
        "          \"%s is intended for use with Uber's Horovod distributed training \"\n",
        "          \"framework. To create a Docker image with Horovod support see \"\n",
        "          \"docker-examples/Dockerfile.horovod.\" % __file__)\n",
        "    raise\n",
        "\n",
        "print(tf.__file__)\n",
        "print(hvd.__file__)\n",
        "\n",
        "__version__ = \"1.0\"\n",
        "\n",
        "def tensorflow_version_tuple():\n",
        "    v = tf.__version__\n",
        "    major, minor, patch = v.split('.')\n",
        "    return (int(major), int(minor), patch)\n",
        "\n",
        "hvd.init()\n",
        "\n",
        "def print_r0(*args, **kwargs):\n",
        "    if hvd.rank() == 0:\n",
        "        print(*args, **kwargs)\n",
        "\n",
        "def float32_variable_storage_getter(getter, name, shape=None, dtype=None,\n",
        "                                    initializer=None, regularizer=None,\n",
        "                                    trainable=True,\n",
        "                                    *args, **kwargs):\n",
        "    storage_dtype = tf.float32 if trainable else dtype\n",
        "    variable = getter(name, shape, dtype=storage_dtype,\n",
        "                      initializer=initializer, regularizer=regularizer,\n",
        "                      trainable=trainable,\n",
        "                      *args, **kwargs)\n",
        "    if trainable and dtype != tf.float32:\n",
        "        variable = tf.cast(variable, dtype)\n",
        "    return variable\n",
        "\n",
        "class GPUNetworkBuilder(object):\n",
        "    \"\"\"This class provides convenient methods for constructing feed-forward\n",
        "    networks with internal data layout of 'NCHW'.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 is_training,\n",
        "                 dtype=tf.float32,\n",
        "                 activation='RELU',\n",
        "                 use_batch_norm=True,\n",
        "                 batch_norm_config = {'decay':   0.9,\n",
        "                                      'epsilon': 1e-4,\n",
        "                                      'scale':   True,\n",
        "                                      'zero_debias_moving_mean': False}):\n",
        "        self.dtype             = dtype\n",
        "        self.activation_func   = activation\n",
        "        self.is_training       = is_training\n",
        "        self.use_batch_norm    = use_batch_norm\n",
        "        self.batch_norm_config = batch_norm_config\n",
        "        self._layer_counts     = defaultdict(lambda: 0)\n",
        "    def _count_layer(self, layer_type):\n",
        "        idx  = self._layer_counts[layer_type]\n",
        "        name = layer_type + str(idx)\n",
        "        self._layer_counts[layer_type] += 1\n",
        "        return name\n",
        "    def _get_variable(self, name, shape, dtype=None,\n",
        "                      initializer=None, seed=None):\n",
        "        if dtype is None:\n",
        "            dtype = self.dtype\n",
        "        if initializer is None:\n",
        "            initializer = init_ops.glorot_uniform_initializer(seed=seed)\n",
        "        elif (isinstance(initializer, float) or\n",
        "              isinstance(initializer, int)):\n",
        "            initializer = tf.constant_initializer(float(initializer))\n",
        "        return tf.get_variable(name, shape, dtype, initializer)\n",
        "    def _to_nhwc(self, x):\n",
        "        return tf.transpose(x, [0,2,3,1])\n",
        "    def _from_nhwc(self, x):\n",
        "        return tf.transpose(x, [0,3,1,2])\n",
        "    def _bias(self, input_layer):\n",
        "        num_outputs = input_layer.get_shape().as_list()[1]\n",
        "        biases = self._get_variable('biases', [num_outputs], input_layer.dtype,\n",
        "                                    initializer=0)\n",
        "        if len(input_layer.get_shape()) == 4:\n",
        "            return tf.nn.bias_add(input_layer, biases,\n",
        "                                  data_format='NCHW')\n",
        "        else:\n",
        "            return input_layer + biases\n",
        "    def _batch_norm(self, input_layer, scope):\n",
        "        return tf.contrib.layers.batch_norm(input_layer,\n",
        "                                            is_training=self.is_training,\n",
        "                                            scope=scope,\n",
        "                                            data_format='NCHW',\n",
        "                                            fused=True,\n",
        "                                            **self.batch_norm_config)\n",
        "    def _bias_or_batch_norm(self, input_layer, scope, use_batch_norm):\n",
        "        if use_batch_norm is None:\n",
        "            use_batch_norm = self.use_batch_norm\n",
        "        if use_batch_norm:\n",
        "            return self._batch_norm(input_layer, scope)\n",
        "        else:\n",
        "            return self._bias(input_layer)\n",
        "    def input_layer(self, input_layer):\n",
        "        \"\"\"Converts input data into the internal format\"\"\"\n",
        "        x = self._from_nhwc(input_layer)\n",
        "        x = tf.cast(x, self.dtype)\n",
        "        # Rescale and shift to [-1,1]\n",
        "        x = x * (1./127.5) - 1\n",
        "        return x\n",
        "    def conv(self, input_layer, num_filters, filter_size,\n",
        "             filter_strides=(1,1), padding='SAME',\n",
        "             activation=None, use_batch_norm=None):\n",
        "        \"\"\"Applies a 2D convolution layer that includes bias or batch-norm\n",
        "        and an activation function.\n",
        "        \"\"\"\n",
        "        num_inputs = input_layer.get_shape().as_list()[1]\n",
        "        kernel_shape = [filter_size[0], filter_size[1],\n",
        "                        num_inputs, num_filters]\n",
        "        strides = [1, 1, filter_strides[0], filter_strides[1]]\n",
        "        with tf.variable_scope(self._count_layer('conv')) as scope:\n",
        "            kernel = self._get_variable('weights', kernel_shape,\n",
        "                                        input_layer.dtype)\n",
        "            if padding == 'SAME_RESNET': # ResNet models require custom padding\n",
        "                kh, kw = filter_size\n",
        "                rate = 1\n",
        "                kernel_size_effective = kh + (kw - 1) * (rate - 1)\n",
        "                pad_total = kernel_size_effective - 1\n",
        "                pad_beg = pad_total // 2\n",
        "                pad_end = pad_total - pad_beg\n",
        "                padding = [[0, 0], [0, 0],\n",
        "                           [pad_beg, pad_end], [pad_beg, pad_end]]\n",
        "                input_layer = tf.pad(input_layer, padding)\n",
        "                padding = 'VALID'\n",
        "            x = tf.nn.conv2d(input_layer, kernel, strides,\n",
        "                             padding=padding, data_format='NCHW')\n",
        "            x = self._bias_or_batch_norm(x, scope, use_batch_norm)\n",
        "            x = self.activate(x, activation)\n",
        "            return x\n",
        "    def deconv(self, input_layer, num_filters, filter_size,\n",
        "               filter_strides=(2,2), padding='SAME',\n",
        "               activation=None, use_batch_norm=None):\n",
        "        \"\"\"Applies a 'transposed convolution' layer that includes bias or\n",
        "        batch-norm and an activation function.\n",
        "        \"\"\"\n",
        "        num_inputs  = input_layer.get_shape().as_list()[1]\n",
        "        ih, iw      = input_layer.get_shape().as_list()[2:]\n",
        "        output_shape = [-1, num_filters,\n",
        "                        ih*filter_strides[0], iw*filter_strides[1]]\n",
        "        kernel_shape = [filter_size[0], filter_size[1],\n",
        "                        num_filters, num_inputs]\n",
        "        strides = [1, 1, filter_strides[0], filter_strides[1]]\n",
        "        with tf.variable_scope(self._count_layer('deconv')) as scope:\n",
        "            kernel = self._get_variable('weights', kernel_shape,\n",
        "                                        input_layer.dtype)\n",
        "            x = tf.nn.conv2d_transpose(input_layer, kernel, output_shape,\n",
        "                                       strides, padding=padding,\n",
        "                                       data_format='NCHW')\n",
        "            x = self._bias_or_batch_norm(x, scope, use_batch_norm)\n",
        "            x = self.activate(x, activation)\n",
        "            return x\n",
        "    def activate(self, input_layer, funcname=None):\n",
        "        \"\"\"Applies an activation function\"\"\"\n",
        "        if isinstance(funcname, tuple):\n",
        "            funcname = funcname[0]\n",
        "            params = funcname[1:]\n",
        "        if funcname is None:\n",
        "            funcname = self.activation_func\n",
        "        if funcname == 'LINEAR':\n",
        "            return input_layer\n",
        "        activation_map = {\n",
        "            'RELU':    tf.nn.relu,\n",
        "            'RELU6':   tf.nn.relu6,\n",
        "            'ELU':     tf.nn.elu,\n",
        "            'SIGMOID': tf.nn.sigmoid,\n",
        "            'TANH':    tf.nn.tanh,\n",
        "            'LRELU':   lambda x, name: tf.maximum(params[0]*x, x, name=name)\n",
        "        }\n",
        "        return activation_map[funcname](input_layer, name=funcname.lower())\n",
        "    def pool(self, input_layer, funcname, window_size,\n",
        "                 window_strides=(2,2),\n",
        "                 padding='VALID'):\n",
        "        \"\"\"Applies spatial pooling\"\"\"\n",
        "        pool_map = {\n",
        "            'MAX': tf.nn.max_pool,\n",
        "            'AVG': tf.nn.avg_pool\n",
        "        }\n",
        "        kernel_size    = [1, 1, window_size[0], window_size[1]]\n",
        "        kernel_strides = [1, 1, window_strides[0], window_strides[1]]\n",
        "        return pool_map[funcname](input_layer, kernel_size, kernel_strides,\n",
        "                                  padding, data_format='NCHW',\n",
        "                                  name=funcname.lower())\n",
        "    def project(self, input_layer, num_outputs, height, width,\n",
        "                activation=None):\n",
        "        \"\"\"Linearly projects to an image-like tensor\"\"\"\n",
        "        with tf.variable_scope(self._count_layer('project')):\n",
        "            x = self.fully_connected(input_layer, num_outputs*height*width,\n",
        "                                     activation=activation)\n",
        "            x = tf.reshape(x, [-1, num_outputs, height, width])\n",
        "            return x\n",
        "    def flatten(self, input_layer):\n",
        "        \"\"\"Flattens the spatial and channel dims into a single dim (4D->2D)\"\"\"\n",
        "        # Note: This ensures the output order matches that of NHWC networks\n",
        "        input_layer = self._to_nhwc(input_layer)\n",
        "        input_shape = input_layer.get_shape().as_list()\n",
        "        num_inputs  = input_shape[1]*input_shape[2]*input_shape[3]\n",
        "        return tf.reshape(input_layer, [-1, num_inputs], name='flatten')\n",
        "    def spatial_avg(self, input_layer):\n",
        "        \"\"\"Averages over spatial dimensions (4D->2D)\"\"\"\n",
        "        return tf.reduce_mean(input_layer, [2, 3], name='spatial_avg')\n",
        "    def fully_connected(self, input_layer, num_outputs, activation=None):\n",
        "        \"\"\"Applies a fully-connected set of weights\"\"\"\n",
        "        num_inputs = input_layer.get_shape().as_list()[1]\n",
        "        kernel_size = [num_inputs, num_outputs]\n",
        "        with tf.variable_scope(self._count_layer('fully_connected')):\n",
        "            kernel = self._get_variable('weights', kernel_size,\n",
        "                                        input_layer.dtype)\n",
        "            x = tf.matmul(input_layer, kernel)\n",
        "            x = self._bias(x)\n",
        "            x = self.activate(x, activation)\n",
        "            return x\n",
        "    def inception_module(self, input_layer, name, cols):\n",
        "        \"\"\"Applies an inception module with a given form\"\"\"\n",
        "        with tf.name_scope(name):\n",
        "            col_layers      = []\n",
        "            col_layer_sizes = []\n",
        "            for c, col in enumerate(cols):\n",
        "                col_layers.append([])\n",
        "                col_layer_sizes.append([])\n",
        "                x = input_layer\n",
        "                for l, layer in enumerate(col):\n",
        "                    ltype, args = layer[0], layer[1:]\n",
        "                    if   ltype == 'conv': x = self.conv(x, *args)\n",
        "                    elif ltype == 'pool': x = self.pool(x, *args)\n",
        "                    elif ltype == 'share':\n",
        "                        # Share matching layer from previous column\n",
        "                        x = col_layers[c-1][l]\n",
        "                    else: raise KeyError(\"Invalid layer type for \" +\n",
        "                                         \"inception module: '%s'\" % ltype)\n",
        "                    col_layers[c].append(x)\n",
        "            catdim  = 1\n",
        "            catvals = [layers[-1] for layers in col_layers]\n",
        "            x = tf.concat(catvals, catdim)\n",
        "            return x\n",
        "    def residual(self, input_layer, net, scale=1.0, activation='RELU'):\n",
        "        \"\"\"Applies a residual layer\"\"\"\n",
        "        input_size     = input_layer.get_shape().as_list()\n",
        "        num_inputs     = input_size[1]\n",
        "        output_layer   = scale*net(self, input_layer)\n",
        "        output_size    = output_layer.get_shape().as_list()\n",
        "        num_outputs    = output_size[1]\n",
        "        kernel_strides = (input_size[2]//output_size[2],\n",
        "                          input_size[3]//output_size[3])\n",
        "        with tf.name_scope('residual'):\n",
        "            if (num_outputs != num_inputs or\n",
        "                kernel_strides[0] != 1 or\n",
        "                kernel_strides[1] != 1):\n",
        "                input_layer = self.conv(input_layer, num_outputs, [1, 1],\n",
        "                                        kernel_strides, activation='LINEAR')\n",
        "            x = self.activate(input_layer + output_layer, activation)\n",
        "            return x\n",
        "    def dropout(self, input_layer, keep_prob=0.5):\n",
        "        \"\"\"Applies a dropout layer if is_training\"\"\"\n",
        "        if self.is_training:\n",
        "            dtype = input_layer.dtype\n",
        "            with tf.variable_scope(self._count_layer('dropout')):\n",
        "                keep_prob_tensor = tf.constant(keep_prob, dtype=dtype)\n",
        "                return tf.nn.dropout(input_layer, keep_prob_tensor)\n",
        "        else:\n",
        "            return input_layer\n",
        "\n",
        "def deserialize_image_record(record):\n",
        "    feature_map = {\n",
        "        'image/encoded':          tf.FixedLenFeature([ ], tf.string, ''),\n",
        "        'image/class/label':      tf.FixedLenFeature([1], tf.int64,  -1),\n",
        "        'image/class/text':       tf.FixedLenFeature([ ], tf.string, ''),\n",
        "        'image/object/bbox/xmin': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'image/object/bbox/ymin': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'image/object/bbox/xmax': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'image/object/bbox/ymax': tf.VarLenFeature(dtype=tf.float32)\n",
        "    }\n",
        "    with tf.name_scope('deserialize_image_record'):\n",
        "        obj = tf.parse_single_example(record, feature_map)\n",
        "        imgdata = obj['image/encoded']\n",
        "        label   = tf.cast(obj['image/class/label'], tf.int32)\n",
        "        bbox    = tf.stack([obj['image/object/bbox/%s'%x].values\n",
        "                            for x in ['ymin', 'xmin', 'ymax', 'xmax']])\n",
        "        bbox = tf.transpose(tf.expand_dims(bbox, 0), [0,2,1])\n",
        "        text    = obj['image/class/text']\n",
        "        return imgdata, label, bbox, text\n",
        "\n",
        "def decode_jpeg(imgdata, channels=3):\n",
        "    return tf.image.decode_jpeg(imgdata, channels=channels,\n",
        "                                fancy_upscaling=False,\n",
        "                                dct_method='INTEGER_FAST')\n",
        "\n",
        "def decode_png(imgdata, channels=3):\n",
        "    return tf.image.decode_png(imgdata, channels=channels)\n",
        "\n",
        "def random_crop_and_resize_image(image, bbox, height, width):\n",
        "    with tf.name_scope('random_crop_and_resize'):\n",
        "        if FLAGS.eval:\n",
        "            image = tf.image.central_crop(image, 224./256.)\n",
        "        else:\n",
        "            bbox_begin, bbox_size, distorted_bbox = tf.image.sample_distorted_bounding_box(\n",
        "                tf.shape(image),\n",
        "                bounding_boxes=bbox,\n",
        "                min_object_covered=0.1,\n",
        "                aspect_ratio_range=[0.8, 1.25],\n",
        "                area_range=[0.1, 1.0],\n",
        "                max_attempts=100,\n",
        "                use_image_if_no_bounding_boxes=True)\n",
        "            # Crop the image to the distorted bounding box\n",
        "            image = tf.slice(image, bbox_begin, bbox_size)\n",
        "        # Resize to the desired output size\n",
        "        image = tf.image.resize_images(\n",
        "            image,\n",
        "            [height, width],\n",
        "            tf.image.ResizeMethod.BILINEAR,\n",
        "            align_corners=False)\n",
        "        image.set_shape([height, width, 3])\n",
        "        return image\n",
        "\n",
        "def distort_image_color(image, order):\n",
        "    with tf.name_scope('distort_color'):\n",
        "        image /= 255.\n",
        "        brightness = lambda img: tf.image.random_brightness(img, max_delta=32. / 255.)\n",
        "        saturation = lambda img: tf.image.random_saturation(img, lower=0.5, upper=1.5)\n",
        "        hue        = lambda img: tf.image.random_hue(img, max_delta=0.2)\n",
        "        contrast   = lambda img: tf.image.random_contrast(img, lower=0.5, upper=1.5)\n",
        "        if order == 0: ops = [brightness, saturation, hue, contrast]\n",
        "        else:          ops = [brightness, contrast, saturation, hue]\n",
        "        for op in ops:\n",
        "            image = op(image)\n",
        "        # The random_* ops do not necessarily clamp the output range\n",
        "        image = tf.clip_by_value(image, 0.0, 1.0)\n",
        "        # Restore the original scaling\n",
        "        image *= 255\n",
        "        return image\n",
        "\n",
        "class DummyPreprocessor(object):\n",
        "    def __init__(self, height, width, batch, nclass):\n",
        "        self.height = height\n",
        "        self.width  = width\n",
        "        self.batch = batch\n",
        "        self.nclass = nclass\n",
        "\n",
        "class ImagePreprocessor(object):\n",
        "    def __init__(self, height, width, subset='train', dtype=tf.uint8):\n",
        "        self.height = height\n",
        "        self.width  = width\n",
        "        self.subset = subset\n",
        "        self.dtype = dtype\n",
        "        self.nsummary = 10 # Max no. images to generate summaries for\n",
        "    def preprocess(self, imgdata, bbox, thread_id):\n",
        "        with tf.name_scope('preprocess_image'):\n",
        "            try:\n",
        "                image = decode_jpeg(imgdata)\n",
        "            except:\n",
        "                image = decode_png(imgdata)\n",
        "            if thread_id < self.nsummary:\n",
        "                image_with_bbox = tf.image.draw_bounding_boxes(\n",
        "                    tf.expand_dims(tf.to_float(image), 0), bbox)\n",
        "                tf.summary.image('original_image_and_bbox', image_with_bbox)\n",
        "            image = random_crop_and_resize_image(image, bbox,\n",
        "                                                 self.height, self.width)\n",
        "            if thread_id < self.nsummary:\n",
        "                tf.summary.image('cropped_resized_image',\n",
        "                                 tf.expand_dims(image, 0))\n",
        "            if not FLAGS.eval:\n",
        "                image = tf.image.random_flip_left_right(image)\n",
        "            if thread_id < self.nsummary:\n",
        "                tf.summary.image('flipped_image',\n",
        "                                 tf.expand_dims(image, 0))\n",
        "            if FLAGS.distort_color and not FLAGS.eval:\n",
        "                image = distort_image_color(image, order=thread_id%2)\n",
        "                if thread_id < self.nsummary:\n",
        "                    tf.summary.image('distorted_color_image',\n",
        "                                     tf.expand_dims(image, 0))\n",
        "        return image\n",
        "    def minibatch(self, batch_size):\n",
        "        record_input = data_flow_ops.RecordInput(\n",
        "            file_pattern=os.path.join(FLAGS.data_dir, '%s-*' % self.subset),\n",
        "            parallelism=64,\n",
        "            seed=301+hvd.rank(),\n",
        "            # Note: This causes deadlock during init if larger than dataset\n",
        "            buffer_size=FLAGS.input_buffer_size,\n",
        "            batch_size=batch_size)\n",
        "        records = record_input.get_yield_op()\n",
        "        # Split batch into individual images\n",
        "        records = tf.split(records, batch_size, 0)\n",
        "        records = [tf.reshape(record, []) for record in records]\n",
        "        # Deserialize and preprocess images into batches for each device\n",
        "        images = []\n",
        "        labels = []\n",
        "        with tf.name_scope('input_pipeline'):\n",
        "            for i, record in enumerate(records):\n",
        "                imgdata, label, bbox, text = deserialize_image_record(record)\n",
        "                image = self.preprocess(imgdata, bbox, thread_id=i)\n",
        "                label -= 1 # Change to 0-based (don't use background class)\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "            # Stack images back into a single tensor\n",
        "            images = tf.parallel_stack(images)\n",
        "            labels = tf.concat(labels, 0)\n",
        "            images = tf.reshape(images, [-1, self.height, self.width, 3])\n",
        "            images = tf.clip_by_value(images, 0., 255.)\n",
        "            images = tf.cast(images, self.dtype)\n",
        "        return images, labels\n",
        "\n",
        "def stage(tensors):\n",
        "    \"\"\"Stages the given tensors in a StagingArea for asynchronous put/get.\n",
        "    \"\"\"\n",
        "    stage_area = data_flow_ops.StagingArea(\n",
        "        dtypes=[tensor.dtype       for tensor in tensors],\n",
        "        shapes=[tensor.get_shape() for tensor in tensors])\n",
        "    put_op      = stage_area.put(tensors)\n",
        "    get_tensors = stage_area.get()\n",
        "\n",
        "    get_tensors = [tf.reshape(gt, t.get_shape())\n",
        "                   for (gt,t) in zip(get_tensors, tensors)]\n",
        "    return put_op, get_tensors\n",
        "\n",
        "\n",
        "class FeedForwardTrainer(object):\n",
        "    def __init__(self, preprocessor, loss_func, nstep_per_epoch=None):\n",
        "        self.image_preprocessor = preprocessor\n",
        "        self.loss_func          = loss_func\n",
        "        with tf.device('/cpu:0'):\n",
        "            self.global_step = tf.get_variable(\n",
        "                'global_step', [],\n",
        "                initializer=tf.constant_initializer(0),\n",
        "                dtype=tf.int64,\n",
        "                trainable=False)\n",
        "        if FLAGS.lr_decay_policy == 'poly':\n",
        "            self.learning_rate = tf.train.polynomial_decay(\n",
        "                FLAGS.learning_rate,\n",
        "                self.global_step,\n",
        "                decay_steps=FLAGS.num_epochs*nstep_per_epoch,\n",
        "                end_learning_rate=0.,\n",
        "                power=FLAGS.lr_poly_power,\n",
        "                cycle=False)\n",
        "        else:\n",
        "            boundary_epochs = [30, 60, 80, 90]\n",
        "            decay_rates = [1, 0.1, 0.01, 0.001, 1e-4]\n",
        "            base_lr = 0.128\n",
        "            batch_size = 16*256\n",
        "            batch_denom = 1024 #256\n",
        "            num_images = 1281000\n",
        "            batches_per_epoch = num_images // batch_size \n",
        "            initial_learning_rate = base_lr * batch_size / batch_denom\n",
        "            boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]\n",
        "            vals = [initial_learning_rate * decay for decay in decay_rates]\n",
        "\n",
        "            def learning_rate_fn(global_step):\n",
        "                #lr = tf.train.piecewise_constant(global_step, boundaries, vals)\n",
        "                lr = tf.train.polynomial_decay(\n",
        "                    initial_learning_rate,\n",
        "                    self.global_step,\n",
        "                    decay_steps=FLAGS.num_epochs*nstep_per_epoch,\n",
        "                    end_learning_rate=0.,\n",
        "                    power=FLAGS.lr_poly_power,\n",
        "                    cycle=False)\n",
        "                warmup_steps = int(batches_per_epoch * 5)\n",
        "                warmup_lr = (\n",
        "                    initial_learning_rate * tf.cast(global_step, tf.float32) / tf.cast(\n",
        "                    warmup_steps, tf.float32))\n",
        "                return tf.cond(global_step < warmup_steps, lambda: warmup_lr, lambda: lr)\n",
        "\n",
        "            self.learning_rate = learning_rate_fn(self.global_step)\n",
        "\n",
        "\n",
        "#            boundaries = [9360, 18720, 24960]\n",
        "#            values = [0.1, 0.01, 0.001, 0.0001]\n",
        "#            self.learning_rate = tf.train.piecewise_constant(self.global_step, boundaries, values)\n",
        "\n",
        "#            self.learning_rate = tf.train.exponential_decay(\n",
        "#                FLAGS.learning_rate,\n",
        "##                self.global_step,\n",
        "#                decay_steps=FLAGS.lr_decay_epochs*nstep_per_epoch,\n",
        "#                decay_rate=FLAGS.lr_decay_rate,\n",
        "#                staircase=True)\n",
        "    def training_step(self, batch_size):\n",
        "        if type(self.image_preprocessor) is not DummyPreprocessor:\n",
        "            with tf.device('/cpu:0'):\n",
        "                images, labels = self.image_preprocessor.minibatch(batch_size)\n",
        "                # Stage images on the host\n",
        "                preload_op, (images, labels) = stage([images, labels])\n",
        "            with tf.device('/gpu:0'):\n",
        "                # Copy images from host to device\n",
        "                gpucopy_op, (images, labels) = stage([images, labels])\n",
        "        else:\n",
        "            with tf.device('/gpu:0'):\n",
        "                input_shape = [self.image_preprocessor.batch, \n",
        "                               self.image_preprocessor.height,\n",
        "                               self.image_preprocessor.width,\n",
        "                               3]\n",
        "                images = tf.truncated_normal(\n",
        "                    input_shape,\n",
        "                    dtype=tf.float32,\n",
        "                    stddev=1.e-1,\n",
        "                    name='synthetic_images')\n",
        "                labels = tf.random_uniform(\n",
        "                    [self.image_preprocessor.batch],\n",
        "                    minval=0,\n",
        "                    maxval=self.image_preprocessor.nclass-1,\n",
        "                    dtype=tf.int32,\n",
        "                    name='synthetic_labels')\n",
        "                preload_op, (images, labels) = stage([images, labels])\n",
        "                gpucopy_op = None\n",
        "\n",
        "        with tf.device('/gpu:0'):\n",
        "            # Evaluate the loss and compute the gradients\n",
        "            with tf.variable_scope(\n",
        "                    'GPU_0',\n",
        "                    # Force all variables to be stored as float32\n",
        "                    custom_getter=float32_variable_storage_getter) as var_scope:\n",
        "                loss, logits = self.loss_func(images, labels, var_scope)\n",
        " \n",
        "        with tf.device('/cpu:0'): # No in_top_k implem on GPU\n",
        "            top1 = tf.reduce_mean(\n",
        "                tf.cast(tf.nn.in_top_k(logits, labels, 1), tf.float32))\n",
        "            top5 = tf.reduce_mean(\n",
        "                tf.cast(tf.nn.in_top_k(logits, labels, 5), tf.float32))\n",
        "\n",
        "            averager = tf.train.ExponentialMovingAverage(0.90, name='loss_avg',\n",
        "                                                         zero_debias=True)\n",
        "            avg_op = averager.apply([loss])\n",
        "            loss_avg = averager.average(loss)\n",
        "            # Note: This must be done _after_ the averager.average() call\n",
        "            #         because it changes total_loss into a new object.\n",
        "            with tf.control_dependencies([avg_op]):\n",
        "                total_loss     = tf.identity(loss)\n",
        "                total_loss_avg = tf.identity(loss_avg)\n",
        "            tf.summary.scalar('total_loss_raw', total_loss)\n",
        "            tf.summary.scalar('total_loss_avg', total_loss_avg)\n",
        "            tf.summary.scalar('Top-1_accuracy', 100.*top1)\n",
        "            tf.summary.scalar('Top-5_accuracy', 100.*top5)\n",
        "            tf.summary.scalar('learning_rate', self.learning_rate)\n",
        "\n",
        "        # Apply the gradients to optimize the loss function\n",
        "        with tf.device('/gpu:0'):\n",
        "            opt = tf.train.MomentumOptimizer(self.learning_rate, FLAGS.momentum,\n",
        "                                             use_nesterov=True)\n",
        "            opt = hvd.DistributedOptimizer(opt)\n",
        "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) or []\n",
        "            with tf.control_dependencies(update_ops):\n",
        "                if FLAGS.loss_scale != 1:\n",
        "                    loss = loss * float(FLAGS.loss_scale)\n",
        "                gradvars = opt.compute_gradients(loss,\n",
        "                    gate_gradients=tf.train.Optimizer.GATE_NONE)\n",
        "                if FLAGS.loss_scale != 1:\n",
        "                    inv_scale = 1. / float(FLAGS.loss_scale)\n",
        "                    gradvars = [(grad * inv_scale, var)\n",
        "                                for grad, var in gradvars]\n",
        "\n",
        "            if FLAGS.LARC_eta is not None:\n",
        "                LARC_eta = float(FLAGS.LARC_eta)\n",
        "                LARC_epsilon = float(FLAGS.LARC_epsilon)\n",
        "                v_list = [tf.norm(tensor=v, ord=2) for _, v in gradvars]\n",
        "                g_list = [tf.norm(tensor=g, ord=2) if g is not None else 0.0\n",
        "                          for g, _ in gradvars ]\n",
        "                v_norms = tf.stack(v_list)\n",
        "                g_norms = tf.stack(g_list)\n",
        "                zeds = tf.zeros_like(v_norms)\n",
        "                cond = tf.logical_and(\n",
        "                    tf.not_equal(v_norms, zeds),\n",
        "                    tf.not_equal(g_norms, zeds))\n",
        "                true_vals = tf.scalar_mul(LARC_eta, tf.div(v_norms, g_norms))\n",
        "                false_vals = tf.fill(tf.shape(v_norms), LARC_epsilon)\n",
        "                larc_local_lr = tf.where(cond, true_vals, false_vals)\n",
        "                if FLAGS.LARC_mode != \"scale\":\n",
        "                    ones = tf.ones_like(v_norms)\n",
        "                    lr = tf.fill(tf.shape(v_norms), self.learning_rate)\n",
        "                    larc_local_lr = tf.minimum(tf.div(larc_local_lr, lr), ones)\n",
        "\n",
        "                gradvars = [(tf.multiply(larc_local_lr[i], g), v)\n",
        "                            if g is not None else (None, v) \n",
        "                            for i, (g, v) in enumerate(gradvars) ]\n",
        "\n",
        "            train_op = opt.apply_gradients(gradvars)\n",
        "\n",
        "        with tf.device('/cpu:0'):\n",
        "            with tf.control_dependencies([train_op]):\n",
        "                increment_global_step_op = tf.assign_add(self.global_step, 1)\n",
        "        self.enqueue_ops = []\n",
        "        self.enqueue_ops.append(preload_op)\n",
        "        if gpucopy_op is not None:\n",
        "            self.enqueue_ops.append(gpucopy_op)\n",
        "        all_training_ops = (self.enqueue_ops + [increment_global_step_op])\n",
        "        return total_loss_avg, self.learning_rate, all_training_ops\n",
        "    def init(self, sess):\n",
        "        init_op = tf.global_variables_initializer()\n",
        "        sess.run(init_op)\n",
        "    def sync(self, sess):\n",
        "        sync_op = hvd.broadcast_global_variables(0)\n",
        "        sess.run(sync_op)\n",
        "    def prefill_pipeline(self, sess):\n",
        "        # Pre-fill the input pipeline with data\n",
        "        for i in range(len(self.enqueue_ops)):\n",
        "            sess.run(self.enqueue_ops[:i+1])\n",
        "\n",
        "class FeedForwardEvaluator(object):\n",
        "    def __init__(self, preprocessor, eval_func):\n",
        "        self.eval_func          = eval_func\n",
        "        self.image_preprocessor = preprocessor\n",
        "    def evaluation_step(self, batch_size):\n",
        "        with tf.device('/cpu:0'):\n",
        "            images, labels = self.image_preprocessor.minibatch(batch_size)\n",
        "            # Stage images on the host\n",
        "            preload_op, (images, labels) = stage([images, labels])\n",
        "        with tf.device('/gpu:0'):\n",
        "            # Copy images from host to device\n",
        "            gpucopy_op, (images, labels) = stage([images, labels])\n",
        "            # Evaluate the loss and compute the gradients\n",
        "            with tf.variable_scope('GPU_0') as var_scope:\n",
        "                top1, top5 = self.eval_func(images, labels, var_scope)\n",
        "        self.enqueue_ops = [preload_op, gpucopy_op]\n",
        "        return top1, top5, self.enqueue_ops\n",
        "    def prefill_pipeline(self, sess):\n",
        "        # Pre-fill the input pipeline with data\n",
        "        for i in range(len(self.enqueue_ops)):\n",
        "            sess.run(self.enqueue_ops[:i+1])\n",
        "\n",
        "def inference_trivial(net, input_layer):\n",
        "    \"\"\"A trivial model for benchmarking input pipeline performance\"\"\"\n",
        "    net.use_batch_norm = False\n",
        "    x = net.input_layer(input_layer)\n",
        "    x = net.flatten(x)\n",
        "    x = net.fully_connected(x, 1)\n",
        "    return x\n",
        "\n",
        "def inference_lenet5(net, input_layer):\n",
        "    \"\"\"Tiny network matching TF's MNIST tutorial model\"\"\"\n",
        "    net.use_batch_norm = False\n",
        "    x = net.input_layer(input_layer)\n",
        "    x = net.conv(x, 32,    (5,5))\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    x = net.conv(x, 64,    (5,5))\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    x = net.flatten(x)\n",
        "    x = net.fully_connected(x, 512)\n",
        "    return x\n",
        "\n",
        "def inference_overfeat(net, input_layer):\n",
        "    net.use_batch_norm = False\n",
        "    x = net.input_layer(input_layer)\n",
        "    x = net.conv(x, 96,   (11,11), (4,4), 'VALID')\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    x = net.conv(x, 256,   (5,5), (1,1), 'VALID')\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    x = net.conv(x, 512,   (3,3))\n",
        "    x = net.conv(x, 1024,  (3,3))\n",
        "    x = net.conv(x, 1024,  (3,3))\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    x = net.flatten(x)\n",
        "    x = net.fully_connected(x, 3072)\n",
        "    x = net.fully_connected(x, 4096)\n",
        "    return x\n",
        "\n",
        "def inference_alexnet_owt(net, input_layer):\n",
        "    \"\"\"Alexnet One Weird Trick model\n",
        "    https://arxiv.org/abs/1404.5997\n",
        "    \"\"\"\n",
        "    net.use_batch_norm = False\n",
        "    x = net.input_layer(input_layer)\n",
        "    # Note: VALID requires padding the images by 3 in width and height\n",
        "    x = net.conv(x, 64, (11,11), (4,4), 'VALID')\n",
        "    x = net.pool(x, 'MAX', (3,3))\n",
        "    x = net.conv(x, 192,   (5,5))\n",
        "    x = net.pool(x, 'MAX', (3,3))\n",
        "    x = net.conv(x, 384,   (3,3))\n",
        "    x = net.conv(x, 256,   (3,3))\n",
        "    x = net.conv(x, 256,   (3,3))\n",
        "    x = net.pool(x, 'MAX', (3,3))\n",
        "    x = net.flatten(x)\n",
        "    x = net.fully_connected(x, 4096)\n",
        "    x = net.dropout(x)\n",
        "    x = net.fully_connected(x, 4096)\n",
        "    x = net.dropout(x)\n",
        "    return x\n",
        "\n",
        "def inference_vgg_impl(net, input_layer, layer_counts):\n",
        "    net.use_batch_norm = False\n",
        "    x = net.input_layer(input_layer)\n",
        "    for _ in range(layer_counts[0]): x = net.conv(x,  64, (3,3))\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    for _ in range(layer_counts[1]): x = net.conv(x, 128, (3,3))\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    for _ in range(layer_counts[2]): x = net.conv(x, 256, (3,3))\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    for _ in range(layer_counts[3]): x = net.conv(x, 512, (3,3))\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    for _ in range(layer_counts[4]): x = net.conv(x, 512, (3,3))\n",
        "    x = net.pool(x, 'MAX', (2,2))\n",
        "    x = net.flatten(x)\n",
        "    x = net.fully_connected(x, 4096)\n",
        "    x = net.fully_connected(x, 4096)\n",
        "    return x\n",
        "def inference_vgg(net, input_layer, nlayer):\n",
        "    \"\"\"Visual Geometry Group's family of models\n",
        "    https://arxiv.org/abs/1409.1556\n",
        "    \"\"\"\n",
        "    if   nlayer == 11: return inference_vgg_impl(net, input_layer, [1,1,2,2,2]) # A\n",
        "    elif nlayer == 13: return inference_vgg_impl(net, input_layer, [2,2,2,2,2]) # B\n",
        "    elif nlayer == 16: return inference_vgg_impl(net, input_layer, [2,2,3,3,3]) # D\n",
        "    elif nlayer == 19: return inference_vgg_impl(net, input_layer, [2,2,4,4,4]) # E\n",
        "    else: raise ValueError(\"Invalid nlayer (%i); must be one of: 11,13,16,19\" %\n",
        "                           nlayer)\n",
        "\n",
        "def inference_googlenet(net, input_layer):\n",
        "    \"\"\"GoogLeNet model\n",
        "    https://arxiv.org/abs/1409.4842\n",
        "    \"\"\"\n",
        "    net.use_batch_norm = False\n",
        "    def inception_v1(net, x, k, l, m, n, p, q):\n",
        "        cols = [[('conv', k, (1,1))],\n",
        "                [('conv', l, (1,1)), ('conv', m, (3,3))],\n",
        "                [('conv', n, (1,1)), ('conv', p, (5,5))],\n",
        "                [('pool', 'MAX', (3,3), (1,1), 'SAME'), ('conv', q, (1,1))]]\n",
        "        return net.inception_module(x, 'incept_v1', cols)\n",
        "    x = net.input_layer(input_layer)\n",
        "    x = net.conv(x,    64, (7,7), (2,2))\n",
        "    x = net.pool(x, 'MAX', (3,3), padding='SAME')\n",
        "    x = net.conv(x,    64, (1,1))\n",
        "    x = net.conv(x,   192, (3,3))\n",
        "    x = net.pool(x, 'MAX', (3,3), padding='SAME')\n",
        "    x = inception_v1(net, x,  64,  96, 128, 16,  32,  32)\n",
        "    x = inception_v1(net, x, 128, 128, 192, 32,  96,  64)\n",
        "    x = net.pool(x, 'MAX', (3,3), padding='SAME')\n",
        "    x = inception_v1(net, x, 192,  96, 208, 16,  48,  64)\n",
        "    x = inception_v1(net, x, 160, 112, 224, 24,  64,  64)\n",
        "    x = inception_v1(net, x, 128, 128, 256, 24,  64,  64)\n",
        "    x = inception_v1(net, x, 112, 144, 288, 32,  64,  64)\n",
        "    x = inception_v1(net, x, 256, 160, 320, 32, 128, 128)\n",
        "    x = net.pool(x, 'MAX', (3,3), padding='SAME')\n",
        "    x = inception_v1(net, x, 256, 160, 320, 32, 128, 128)\n",
        "    x = inception_v1(net, x, 384, 192, 384, 48, 128, 128)\n",
        "    x = net.spatial_avg(x)\n",
        "    return x\n",
        "\n",
        "def inference_inception_v3(net, input_layer):\n",
        "    \"\"\"Google's Inception v3 model\n",
        "    https://arxiv.org/abs/1512.00567\n",
        "    \"\"\"\n",
        "    def inception_v3_a(net, x, n):\n",
        "        cols = [[('conv',  64, (1,1))],\n",
        "                [('conv',  48, (1,1)), ('conv',  64, (5,5))],\n",
        "                [('conv',  64, (1,1)), ('conv',  96, (3,3)), ('conv',  96, (3,3))],\n",
        "                [('pool', 'AVG', (3,3), (1,1), 'SAME'), ('conv',   n, (1,1))]]\n",
        "        return net.inception_module(x, 'incept_v3_a', cols)\n",
        "    def inception_v3_b(net, x):\n",
        "        cols = [[('conv',  64, (1,1)), ('conv',  96, (3,3)), ('conv',  96, (3,3), (2,2), 'VALID')],\n",
        "                [('conv', 384, (3,3), (2,2), 'VALID')],\n",
        "                [('pool', 'MAX', (3,3), (2,2), 'VALID')]]\n",
        "        return net.inception_module(x, 'incept_v3_b', cols)\n",
        "    def inception_v3_c(net, x, n):\n",
        "        cols = [[('conv', 192, (1,1))],\n",
        "                [('conv',   n, (1,1)), ('conv',   n, (1,7)), ('conv', 192, (7,1))],\n",
        "                [('conv',   n, (1,1)), ('conv',   n, (7,1)), ('conv',   n, (1,7)), ('conv',   n, (7,1)), ('conv', 192, (1,7))],\n",
        "                [('pool', 'AVG', (3,3), (1,1), 'SAME'), ('conv', 192, (1,1))]]\n",
        "        return net.inception_module(x, 'incept_v3_c', cols)\n",
        "    def inception_v3_d(net, x):\n",
        "        cols = [[('conv', 192, (1,1)), ('conv', 320, (3,3), (2,2), 'VALID')],\n",
        "                [('conv', 192, (1,1)), ('conv', 192, (1,7)), ('conv', 192, (7,1)), ('conv', 192, (3,3), (2,2), 'VALID')],\n",
        "                [('pool', 'MAX', (3,3), (2,2), 'VALID')]]\n",
        "        return net.inception_module(x, 'incept_v3_d',cols)\n",
        "    def inception_v3_e(net, x, pooltype):\n",
        "        cols = [[('conv', 320, (1,1))],\n",
        "                [('conv', 384, (1,1)), ('conv', 384, (1,3))],\n",
        "                [('share',),           ('conv', 384, (3,1))],\n",
        "                [('conv', 448, (1,1)), ('conv', 384, (3,3)), ('conv', 384, (1,3))],\n",
        "                [('share',),          ('share',),            ('conv', 384, (3,1))],\n",
        "                [('pool', pooltype, (3,3), (1,1), 'SAME'),   ('conv', 192, (1,1))]]\n",
        "        return net.inception_module(x, 'incept_v3_e', cols)\n",
        "\n",
        "    # TODO: This does not include the extra 'arm' that forks off\n",
        "    #         from before the 3rd-last module (the arm is designed\n",
        "    #         to speed up training in the early stages).\n",
        "    net.use_batch_norm = True\n",
        "    x = net.input_layer(input_layer)\n",
        "    x = net.conv(x,    32, (3,3), (2,2), padding='VALID')\n",
        "    x = net.conv(x,    32, (3,3), (1,1), padding='VALID')\n",
        "    x = net.conv(x,    64, (3,3), (1,1), padding='SAME')\n",
        "    x = net.pool(x, 'MAX', (3,3))\n",
        "    x = net.conv(x,    80, (1,1), (1,1), padding='VALID')\n",
        "    x = net.conv(x,   192, (3,3), (1,1), padding='VALID')\n",
        "    x = net.pool(x, 'MAX', (3,3))\n",
        "    x = inception_v3_a(net, x, 32)\n",
        "    x = inception_v3_a(net, x, 64)\n",
        "    x = inception_v3_a(net, x, 64)\n",
        "    x = inception_v3_b(net, x)\n",
        "    x = inception_v3_c(net, x, 128)\n",
        "    x = inception_v3_c(net, x, 160)\n",
        "    x = inception_v3_c(net, x, 160)\n",
        "    x = inception_v3_c(net, x, 192)\n",
        "    x = inception_v3_d(net, x)\n",
        "    x = inception_v3_e(net, x, 'AVG')\n",
        "    x = inception_v3_e(net, x, 'MAX')\n",
        "    x = net.spatial_avg(x)\n",
        "    return x\n",
        "\n",
        "def resnet_bottleneck_v1(net, input_layer, depth, depth_bottleneck, stride,\n",
        "                         basic=False):\n",
        "    num_inputs = input_layer.get_shape().as_list()[1]\n",
        "    x = input_layer\n",
        "    s = stride\n",
        "    with tf.name_scope('resnet_v1'):\n",
        "        if depth == num_inputs:\n",
        "            if stride == 1:\n",
        "                shortcut = input_layer\n",
        "            else:\n",
        "                shortcut = net.pool(x, 'MAX', (1,1), (s,s))\n",
        "        else:\n",
        "            shortcut = net.conv(x, depth, (1,1), (s,s), activation='LINEAR')\n",
        "        if basic:\n",
        "            x = net.conv(x, depth_bottleneck, (3,3), (s,s), padding='SAME_RESNET')\n",
        "            x = net.conv(x, depth,            (3,3), activation='LINEAR')\n",
        "        else:\n",
        "            x = net.conv(x, depth_bottleneck, (1,1), (s,s))\n",
        "            x = net.conv(x, depth_bottleneck, (3,3), padding='SAME')\n",
        "            x = net.conv(x, depth,            (1,1), activation='LINEAR')\n",
        "        x = net.activate(x + shortcut)\n",
        "        return x\n",
        "    \n",
        "def resnext_split_branch(net, input_layer, stride):\n",
        "    x = input_layer\n",
        "    with tf.name_scope('resnext_split_branch'):\n",
        "        x = net.conv(x, net.bottleneck_width, (1, 1), (stride, stride), activation='RELU', use_batch_norm=True)\n",
        "        x = net.conv(x, net.bottleneck_width, (3, 3), (1, 1), activation='RELU', use_batch_norm=True)\n",
        "    return x\n",
        "\n",
        "def resnext_shortcut(net, input_layer, stride, input_size, output_size):\n",
        "    x = input_layer\n",
        "    useConv = net.shortcut_type == 'C' or (net.shortcut_type == 'B' and input_size != output_size)\n",
        "    with tf.name_scope('resnext_shortcut'):\n",
        "        if useConv:\n",
        "            x = net.conv(x, output_size, (1,1), (stride, stride), use_batch_norm=True)\n",
        "        elif output_size == input_size:\n",
        "            if stride == 1:\n",
        "                x = input_layer\n",
        "            else:\n",
        "                x = net.pool(x, 'MAX', (1,1), (stride, stride))\n",
        "        else:\n",
        "            x = input_layer\n",
        "    return x\n",
        "\n",
        "def resnext_bottleneck_v1(net, input_layer, depth, depth_bottleneck, stride):\n",
        "    num_inputs = input_layer.get_shape().as_list()[1]\n",
        "    x = input_layer\n",
        "    with tf.name_scope('resnext_bottleneck_v1'):\n",
        "        shortcut = resnext_shortcut(net, x, stride, num_inputs, depth)\n",
        "        branches_list = []\n",
        "        for i in range(net.cardinality):\n",
        "            branch = resnext_split_branch(net, x, stride)\n",
        "            branches_list.append(branch)\n",
        "        concatenated_branches = tf.concat(values=branches_list, axis=1, name='concat')\n",
        "        bottleneck_depth = concatenated_branches.get_shape().as_list()[1]\n",
        "        x = net.conv(concatenated_branches, depth, (1, 1), (1, 1), activation=None)\n",
        "        x = net.activate(x + shortcut, 'RELU')\n",
        "    return x\n",
        "\n",
        "def inference_residual(net, input_layer, layer_counts, bottleneck_callback):\n",
        "    net.use_batch_norm = True\n",
        "    x = net.input_layer(input_layer)\n",
        "    x = net.conv(x, 64,    (7,7), (2,2), padding='SAME_RESNET')\n",
        "    x = net.pool(x, 'MAX', (3,3), (2,2), padding='SAME')\n",
        "    for i in range(layer_counts[0]):\n",
        "        x = bottleneck_callback(net, x,  256,  64, 1)\n",
        "    for i in range(layer_counts[1]):\n",
        "        x = bottleneck_callback(net, x, 512, 128, 2 if i==0 else 1)\n",
        "    for i in range(layer_counts[2]):\n",
        "        x = bottleneck_callback(net, x, 1024, 256, 2 if i==0 else 1)\n",
        "    for i in range(layer_counts[3]):\n",
        "        x = bottleneck_callback(net, x, 2048, 512, 2 if i==0 else 1)\n",
        "    x = net.spatial_avg(x)\n",
        "    return x\n",
        "\n",
        "def inference_resnet_v1_basic_impl(net, input_layer, layer_counts):\n",
        "    basic_resnet_bottleneck_callback = partial(resnet_bottleneck_v1, basic=True)\n",
        "    return inference_residual(net, input_layer, layer_counts, basic_resnet_bottleneck_callback)\n",
        "\n",
        "def inference_resnet_v1_impl(net, input_layer, layer_counts):\n",
        "    return inference_residual(net, input_layer, layer_counts, resnet_bottleneck_v1)\n",
        "\n",
        "def inference_resnext_v1_impl(net, input_layer, layer_counts):\n",
        "    return inference_residual(net, input_layer, layer_counts, resnext_bottleneck_v1)\n",
        "\n",
        "def inference_resnet_v1(net, input_layer, nlayer):\n",
        "    \"\"\"Deep Residual Networks family of models\n",
        "    https://arxiv.org/abs/1512.03385\n",
        "    \"\"\"\n",
        "    if   nlayer ==  18: return inference_resnet_v1_basic_impl(net, input_layer, [2,2, 2,2])\n",
        "    elif nlayer ==  34: return inference_resnet_v1_basic_impl(net, input_layer, [3,4, 6,3])\n",
        "    elif nlayer ==  50: return inference_resnet_v1_impl(net, input_layer, [3,4, 6,3])\n",
        "    elif nlayer == 101: return inference_resnet_v1_impl(net, input_layer, [3,4,23,3])\n",
        "    elif nlayer == 152: return inference_resnet_v1_impl(net, input_layer, [3,8,36,3])\n",
        "    else: raise ValueError(\"Invalid nlayer (%i); must be one of: 18,34,50,101,152\" %\n",
        "                           nlayer)\n",
        "        \n",
        "def inference_resnext_v1(net, input_layer, nlayer):\n",
        "    \"\"\"Aggregated  Residual Networks family of models\n",
        "    https://arxiv.org/abs/1611.05431\n",
        "    \"\"\"\n",
        "    cardinality_to_bottleneck_width = { 1:64, 2:40, 4:24, 8:14, 32:4 }\n",
        "    net.cardinality = 32\n",
        "    net.shortcut_type = 'B'\n",
        "    assert net.cardinality in cardinality_to_bottleneck_width.keys(), \\\n",
        "    \"Invalid  cardinality (%i); must be one of: 1,2,4,8,32\" % net.cardinality\n",
        "    net.bottleneck_width = cardinality_to_bottleneck_width[net.cardinality]  \n",
        "    if nlayer ==  50: return inference_resnext_v1_impl(net, input_layer, [3,4, 6,3])\n",
        "    elif nlayer == 101: return inference_resnext_v1_impl(net, input_layer, [3,4,23,3])\n",
        "    elif nlayer == 152: return inference_resnext_v1_impl(net, input_layer, [3,8,36,3])\n",
        "    else: raise ValueError(\"Invalid nlayer (%i); must be one of: 50,101,152\" %\n",
        "                           nlayer)\n",
        "\n",
        "# Stem functions\n",
        "def inception_v4_sa(net, x):\n",
        "    cols = [[('pool', 'MAX', (3,3))],\n",
        "            [('conv',  96, (3,3), (2,2), 'VALID')]]\n",
        "    return net.inception_module(x, 'incept_v4_sa', cols)\n",
        "def inception_v4_sb(net, x):\n",
        "    cols = [[('conv',  64, (1,1)), ('conv',  96, (3,3), (1,1), 'VALID')],\n",
        "            [('conv',  64, (1,1)), ('conv',  64, (7,1)), ('conv',  64, (1,7)), ('conv',  96, (3,3), (1,1), 'VALID')]]\n",
        "    return net.inception_module(x, 'incept_v4_sb', cols)\n",
        "def inception_v4_sc(net, x):\n",
        "    cols = [[('conv', 192, (3,3), (2,2), 'VALID')],\n",
        "            [('pool', 'MAX', (3,3))]]\n",
        "    return net.inception_module(x, 'incept_v4_sc', cols)\n",
        "# Reduction functions\n",
        "def inception_v4_ra(net, x, k, l, m, n):\n",
        "    cols = [[('pool', 'MAX', (3,3))],\n",
        "            [('conv',   n, (3,3), (2,2), 'VALID')],\n",
        "            [('conv',   k, (1,1)), ('conv',   l, (3,3)), ('conv',   m, (3,3), (2,2), 'VALID')]]\n",
        "    return net.inception_module(x, 'incept_v4_ra', cols)\n",
        "def inception_v4_rb(net, x):\n",
        "    cols = [[('pool', 'MAX', (3,3))],\n",
        "            [('conv', 192, (1,1)), ('conv', 192, (3,3), (2,2), 'VALID')],\n",
        "            [('conv', 256, (1,1)), ('conv', 256, (1,7)), ('conv', 320, (7,1)), ('conv', 320, (3,3), (2,2), 'VALID')]]\n",
        "    return net.inception_module(x, 'incept_v4_rb', cols)\n",
        "def inception_resnet_v2_rb(net, x):\n",
        "    cols = [[('pool', 'MAX', (3,3))],\n",
        "            # Note: These match Facebook's Torch implem\n",
        "            [('conv', 256, (1,1)), ('conv', 384, (3,3), (2,2), 'VALID')],\n",
        "            [('conv', 256, (1,1)), ('conv', 256, (3,3), (2,2), 'VALID')],\n",
        "            [('conv', 256, (1,1)), ('conv', 256, (3,3)), ('conv', 256, (3,3), (2,2), 'VALID')]]\n",
        "    return net.inception_module(x, 'incept_resnet_v2_rb', cols)\n",
        "\n",
        "def inference_inception_v4(net, input_layer):\n",
        "    \"\"\"Google's Inception v4 model\n",
        "    https://arxiv.org/abs/1602.07261\n",
        "    \"\"\"\n",
        "    def inception_v4_a(net, x):\n",
        "        cols = [[('pool', 'AVG', (3,3), (1,1), 'SAME'), ('conv',  96, (1,1))],\n",
        "                [('conv',  96, (1,1))],\n",
        "                [('conv',  64, (1,1)), ('conv',  96, (3,3))],\n",
        "                [('conv',  64, (1,1)), ('conv',  96, (3,3)), ('conv',  96, (3,3))]]\n",
        "        return net.inception_module(x, 'incept_v4_a', cols)\n",
        "    def inception_v4_b(net, x):\n",
        "        cols = [[('pool', 'AVG', (3,3), (1,1), 'SAME'), ('conv', 128, (1,1))],\n",
        "                [('conv', 384, (1,1))],\n",
        "                [('conv', 192, (1,1)), ('conv', 224, (1,7)), ('conv', 256, (7,1))],\n",
        "                [('conv', 192, (1,1)), ('conv', 192, (1,7)), ('conv', 224, (7,1)), ('conv', 224, (1,7)), ('conv', 256, (7,1))]]\n",
        "        return net.inception_module(x, 'incept_v4_b', cols)\n",
        "    def inception_v4_c(net, x):\n",
        "        cols = [[('pool', 'AVG', (3,3), (1,1), 'SAME'), ('conv', 256, (1,1))],\n",
        "                [('conv', 256, (1,1))],\n",
        "                [('conv', 384, (1,1)), ('conv', 256, (1,3))],\n",
        "                [('share',),           ('conv', 256, (3,1))],\n",
        "                [('conv', 384, (1,1)), ('conv', 448, (1,3)), ('conv', 512, (3,1)), ('conv', 256, (3,1))],\n",
        "                [('share',),           ('share',),           ('share',),           ('conv', 256, (1,3))]]\n",
        "        return net.inception_module(x, 'incept_v4_c', cols)\n",
        "\n",
        "    net.use_batch_norm = True\n",
        "    x = net.input_layer(input_layer)\n",
        "    x = net.conv(x, 32, (3,3), (2,2), padding='VALID')\n",
        "    x = net.conv(x, 32, (3,3), (1,1), padding='VALID')\n",
        "    x = net.conv(x, 64, (3,3))\n",
        "    x = inception_v4_sa(net, x)\n",
        "    x = inception_v4_sb(net, x)\n",
        "    x = inception_v4_sc(net, x)\n",
        "    for _ in range(4):\n",
        "        x = inception_v4_a(net, x)\n",
        "    x = inception_v4_ra(net, x, 192, 224, 256, 384)\n",
        "    for _ in range(7):\n",
        "        x = inception_v4_b(net, x)\n",
        "    x = inception_v4_rb(net, x)\n",
        "    for _ in range(3):\n",
        "        x = inception_v4_c(net, x)\n",
        "    x = net.spatial_avg(x)\n",
        "    x = net.dropout(x, 0.8)\n",
        "    return x\n",
        "\n",
        "def inference_inception_resnet_v2(net, input_layer):\n",
        "    \"\"\"Google's Inception-Resnet v2 model\n",
        "    https://arxiv.org/abs/1602.07261\n",
        "    \"\"\"\n",
        "    def inception_resnet_v2_a(net, x):\n",
        "        cols = [[('conv',  32, (1,1))],\n",
        "                [('conv',  32, (1,1)), ('conv',  32, (3,3))],\n",
        "                [('conv',  32, (1,1)), ('conv',  48, (3,3)), ('conv',  64, (3,3))]]\n",
        "        x = net.inception_module(x, 'incept_resnet_v2_a', cols)\n",
        "        x = net.conv(x, 384, (1,1), activation='LINEAR')\n",
        "        return x\n",
        "    def inception_resnet_v2_b(net, x):\n",
        "        cols = [[('conv', 192, (1,1))],\n",
        "                [('conv', 128, (1,1)), ('conv', 160, (1,7)), ('conv', 192, (7,1))]]\n",
        "        x = net.inception_module(x, 'incept_resnet_v2_b', cols)\n",
        "        x = net.conv(x, 1152, (1,1), activation='LINEAR')\n",
        "        return x\n",
        "    def inception_resnet_v2_c(net, x):\n",
        "        cols = [[('conv', 192, (1,1))],\n",
        "                [('conv', 192, (1,1)), ('conv', 224, (1,3)), ('conv', 256, (3,1))]]\n",
        "        x = net.inception_module(x, 'incept_resnet_v2_c', cols)\n",
        "        x = net.conv(x, 2048, (1,1), activation='LINEAR')\n",
        "        return x\n",
        "\n",
        "    net.use_batch_norm = True\n",
        "    residual_scale = 0.2\n",
        "    x = net.input_layer(input_layer)\n",
        "    x = net.conv(x, 32, (3,3), (2,2), padding='VALID')\n",
        "    x = net.conv(x, 32, (3,3), (1,1), padding='VALID')\n",
        "    x = net.conv(x, 64, (3,3))\n",
        "    x = inception_v4_sa(net, x)\n",
        "    x = inception_v4_sb(net, x)\n",
        "    x = inception_v4_sc(net, x)\n",
        "    for _ in range(5):\n",
        "        x = net.residual(x, inception_resnet_v2_a, scale=residual_scale)\n",
        "    x = inception_v4_ra(net, x, 256, 256, 384, 384)\n",
        "    for _ in range(10):\n",
        "        x = net.residual(x, inception_resnet_v2_b, scale=residual_scale)\n",
        "    x = inception_resnet_v2_rb(net, x)\n",
        "    for _ in range(5):\n",
        "        x = net.residual(x, inception_resnet_v2_c, scale=residual_scale)\n",
        "    x = net.spatial_avg(x)\n",
        "    x = net.dropout(x, 0.8)\n",
        "    return x\n",
        "\n",
        "def run_evaluation(nstep, sess, top1_op, top5_op, enqueue_ops, ckpt):\n",
        "    print(\"Evaluating\")\n",
        "    top1s = []\n",
        "    top5s = []\n",
        "    print(\"  Step  Top-1  Top-5\")\n",
        "    for step in range(nstep):\n",
        "        try:\n",
        "            top1, top5 = sess.run([top1_op, top5_op, enqueue_ops])[:2]\n",
        "    #        if step == 0 or (step+1) % FLAGS.display_every == 0:\n",
        "    #            print(\"% 6i %5.1f%% %5.1f%%\" % (step+1, top1*100, top5*100))\n",
        "            top1s.append(top1)\n",
        "            top5s.append(top5)\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"Keyboard interrupt\")\n",
        "            break\n",
        "    nstep = len(top1s)\n",
        "    if nstep == 0:\n",
        "        return\n",
        "    top1s = np.asarray(top1s) * 100.\n",
        "    top5s = np.asarray(top5s) * 100.\n",
        "    top1_mean = np.mean(top1s)\n",
        "    top5_mean = np.mean(top5s)\n",
        "    if nstep > 2:\n",
        "        top1_uncertainty = np.std(top1s, ddof=1) / np.sqrt(float(nstep))\n",
        "        top5_uncertainty = np.std(top5s, ddof=1) / np.sqrt(float(nstep))\n",
        "    else:\n",
        "        top1_uncertainty = float('nan')\n",
        "        top5_uncertainty = float('nan')\n",
        "    top1_madstd = 1.4826*np.median(np.abs(top1s - np.median(top1s)))\n",
        "    top5_madstd = 1.4826*np.median(np.abs(top5s - np.median(top5s)))\n",
        "    print('-' * 64)\n",
        "    #print('Validation Top-1: %.3f %% +/- %.2f (jitter = %.1f)' % (\n",
        "    #    top1_mean, top1_uncertainty, top1_madstd))\n",
        "    #print('Validation Top-5: %.3f %% +/- %.2f (jitter = %.1f)' % (\n",
        "    #    top5_mean, top5_uncertainty, top5_madstd))\n",
        "    #print('-' * 64)\n",
        "    with open('/home/ubuntu/benchmarks/%s.out'%FLAGS.log_dir, 'a') as f:\n",
        "      f.write(str(ckpt)+' '+str(top1_mean)+' '+str(top5_mean)+'\\n')\n",
        "\n",
        "def get_num_records(tf_record_pattern):\n",
        "    def count_records(tf_record_filename):\n",
        "        count = 0\n",
        "        for _ in tf.python_io.tf_record_iterator(tf_record_filename):\n",
        "            count += 1\n",
        "        return count\n",
        "    filenames = sorted(tf.gfile.Glob(tf_record_pattern))\n",
        "    nfile = len(filenames)\n",
        "    return (count_records(filenames[0])*(nfile-1) +\n",
        "            count_records(filenames[-1]))\n",
        "\n",
        "def add_bool_argument(cmdline, shortname, longname=None, default=False, help=None):\n",
        "    if longname is None:\n",
        "        shortname, longname = None, shortname\n",
        "    elif default == True:\n",
        "        raise ValueError(\"\"\"Boolean arguments that are True by default should not have short names.\"\"\")\n",
        "    name = longname[2:]\n",
        "    feature_parser = cmdline.add_mutually_exclusive_group(required=False)\n",
        "    if shortname is not None:\n",
        "        feature_parser.add_argument(shortname, '--'+name, dest=name, action='store_true', help=help, default=default)\n",
        "    else:\n",
        "        feature_parser.add_argument(           '--'+name, dest=name, action='store_true', help=help, default=default)\n",
        "    feature_parser.add_argument('--no'+name, dest=name, action='store_false')\n",
        "    return cmdline\n",
        "\n",
        "def main():\n",
        "    global_start_time = time.time()\n",
        "    tf.set_random_seed(1234+hvd.rank())\n",
        "    np.random.seed(4321+hvd.rank())\n",
        "    cmdline = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "    # Basic options\n",
        "    cmdline.add_argument('-m', '--model', required=True,\n",
        "                         help=\"\"\"Name of model to run:\n",
        "                         trivial, lenet,\n",
        "                         alexnet, googlenet, vgg[11,13,16,19],\n",
        "                         inception[3,4], resnet[18,34,50,101,152],\n",
        "                         resnext[50,101,152], inception-resnet2.\"\"\")\n",
        "    cmdline.add_argument('--data_dir', default=None,\n",
        "                         help=\"\"\"Path to dataset in TFRecord format\n",
        "                         (aka Example protobufs). Files should be\n",
        "                         named 'train-*' and 'validation-*'.\"\"\")\n",
        "    cmdline.add_argument('-b', '--batch_size', default=64, type=int,\n",
        "                         help=\"\"\"Size of each minibatch.\"\"\")\n",
        "    cmdline.add_argument('--num_batches', default=50, type=int,\n",
        "                         help=\"\"\"Number of batches to run.\n",
        "                         Ignored during eval.\"\"\")\n",
        "    cmdline.add_argument('--num_epochs', default=None, type=int,\n",
        "                         help=\"\"\"Number of epochs to run.\n",
        "                         Overrides --num_batches. Ignored during eval.\"\"\")\n",
        "    cmdline.add_argument('--log_dir', default=\"\",\n",
        "                         help=\"\"\"Directory in which to write training\n",
        "                         summaries and checkpoints.\"\"\")\n",
        "    cmdline.add_argument('--display_every', default=1, type=int,\n",
        "                         help=\"\"\"How often (in iterations) to print out\n",
        "                         running information.\"\"\")\n",
        "    cmdline.add_argument('--save_interval', default=43200, type=int,\n",
        "                         help=\"\"\"Time in seconds between checkpoints.\"\"\")\n",
        "    cmdline.add_argument('--summary_interval', default=3600, type=int,\n",
        "                         help=\"\"\"Time in seconds between saves of summary statistics.\"\"\")\n",
        "    add_bool_argument(cmdline, '--eval',\n",
        "                      help=\"\"\"Evaluate the top-1 and top-5 accuracy of\n",
        "                      a checkpointed model.\"\"\")\n",
        "    add_bool_argument(cmdline, '--fp16',\n",
        "                      help=\"\"\"Train using float16 (half) precision instead\n",
        "                      of float32.\"\"\")\n",
        "\n",
        "    global FLAGS\n",
        "    FLAGS, unknown_args = cmdline.parse_known_args()\n",
        "    if len(unknown_args) > 0:\n",
        "        for bad_arg in unknown_args:\n",
        "            print(\"ERROR: Unknown command line arg: %s\" % bad_arg)\n",
        "        raise ValueError(\"Invalid command line arg(s)\")\n",
        "\n",
        "    if not os.path.exists(FLAGS.log_dir):\n",
        "        os.makedirs(FLAGS.log_dir)\n",
        "\n",
        "    # create logger with 'aws-tf-cnn'\n",
        "    logger = logging.getLogger('aws-tf-hvd-cnn')\n",
        "    logger.setLevel(logging.DEBUG)  # INFO, ERROR\n",
        "    # file handler which logs debug messages\n",
        "    fh = logging.FileHandler(os.path.join(FLAGS.log_dir, 'aws-tf-hvd-cnn.log'))\n",
        "    fh.setLevel(logging.DEBUG)\n",
        "    # console handler\n",
        "    ch = logging.StreamHandler()\n",
        "    ch.setLevel(logging.INFO)\n",
        "    # add formatter to the handlers\n",
        "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "    fh.setFormatter(formatter)\n",
        "    ch.setFormatter(formatter)\n",
        "    # add handlers to logger\n",
        "    logger.addHandler(fh)\n",
        "    logger.addHandler(ch)\n",
        "\n",
        "    nclass = 1000\n",
        "    batch_size = FLAGS.batch_size\n",
        "    subset = 'validation' if FLAGS.eval else 'train'\n",
        "\n",
        "    tfversion = tensorflow_version_tuple()\n",
        "    logger.info(\"TensorFlow:  %i.%i.%s\" % tfversion)\n",
        "    logger.info(\"This script: {} v{}\".format(__file__, __version__))\n",
        "    logger.info(\"Parameters specified:\")\n",
        "    logger.info('\\n'.join(['  '+arg for arg in sys.argv[1:]]))\n",
        "\n",
        "    if FLAGS.data_dir is not None and FLAGS.data_dir != '':\n",
        "        nrecord = get_num_records(os.path.join(FLAGS.data_dir, '%s-*' % subset))\n",
        "    else:\n",
        "        nrecord = FLAGS.num_batches * batch_size * hvd.size()\n",
        "\n",
        "    # Training hyperparameters\n",
        "    FLAGS.learning_rate         = 0.001 # Model-specific values are set below\n",
        "    FLAGS.momentum              = 0.0\n",
        "    FLAGS.lr_decay_policy       = 'piecewise' #'poly'\n",
        "    FLAGS.lr_decay_epochs       = 30\n",
        "    FLAGS.lr_decay_rate         = 0.1\n",
        "    FLAGS.lr_poly_power         = 2.\n",
        "    FLAGS.weight_decay          = 1e-4\n",
        "    FLAGS.input_buffer_size     = min(10000, nrecord)\n",
        "    FLAGS.distort_color         = False\n",
        "    FLAGS.nstep_burnin          = 20\n",
        "    FLAGS.loss_scale            = 256. # TODO: May need to decide this based on model\n",
        "    FLAGS.LARC_eta              = None #0.003\n",
        "    FLAGS.LARC_epsilon          = 1.\n",
        "    FLAGS.LARC_mode             = 'clip'\n",
        "\n",
        "    model_dtype = tf.float16 if FLAGS.fp16 else tf.float32\n",
        "\n",
        "    logger.info(\"Num ranks:  {}\".format(hvd.size()))\n",
        "    logger.info(\"Num of images: {}\".format(nrecord)) if FLAGS.data_dir is not None else logger.info('Synthetic')\n",
        "    logger.info(\"Model: {}\".format(FLAGS.model))\n",
        "    logger.info(\"Total batch size: {}\".format(batch_size * hvd.size()))\n",
        "    logger.info(\"{}, per device\".format(batch_size))\n",
        "    logger.info(\"Data format: 'NCHW'\")\n",
        "    logger.info(\"Data type:  fp16\") if model_dtype == tf.float16 else logger.info('Data type:  fp32')\n",
        "\n",
        "    if FLAGS.num_epochs is not None:\n",
        "        if FLAGS.data_dir is None:\n",
        "            logger.error(\"num_epochs requires data_dir to be specified\")\n",
        "            raise ValueError(\"num_epochs requires data_dir to be specified\")\n",
        "        nstep = nrecord * FLAGS.num_epochs // (batch_size * hvd.size())\n",
        "    else:\n",
        "        nstep = FLAGS.num_batches\n",
        "        FLAGS.num_epochs = max(nstep * batch_size * hvd.size() // nrecord, 1)\n",
        "\n",
        "    model_name = FLAGS.model\n",
        "    if   model_name == 'trivial':\n",
        "        height, width = 224, 224\n",
        "        model_func = inference_trivial\n",
        "    elif model_name == 'lenet':\n",
        "        height, width = 28, 28\n",
        "        model_func = inference_lenet5\n",
        "    elif model_name == 'alexnet':\n",
        "        height, width = 227, 227\n",
        "        model_func = inference_alexnet_owt\n",
        "        FLAGS.learning_rate = 0.03\n",
        "    elif model_name == 'overfeat':\n",
        "        height, width = 231, 231\n",
        "        model_func = inference_overfeat\n",
        "    elif model_name.startswith('vgg'):\n",
        "        height, width = 224, 224\n",
        "        nlayer = int(model_name[len('vgg'):])\n",
        "        model_func = lambda net, images: inference_vgg(net, images, nlayer)\n",
        "        FLAGS.learning_rate = 0.02\n",
        "    elif model_name == 'googlenet':\n",
        "        height, width = 224, 224\n",
        "        model_func = inference_googlenet\n",
        "        FLAGS.learning_rate = 0.04\n",
        "    elif model_name == 'inception3':\n",
        "        height, width = 299, 299\n",
        "        model_func = inference_inception_v3\n",
        "        FLAGS.learning_rate = 0.2\n",
        "    elif model_name.startswith('resnet'):\n",
        "        height, width = 224, 224\n",
        "        nlayer = int(model_name[len('resnet'):])\n",
        "        model_func = lambda net, images: inference_resnet_v1(net, images, nlayer)\n",
        "        FLAGS.learning_rate = 1. * (batch_size * hvd.size() / 1024.0) if nlayer > 18 else 0.5\n",
        "    elif model_name.startswith('resnext'):\n",
        "        height, width = 224, 224\n",
        "        nlayer = int(model_name[len('resnext'):])\n",
        "        model_func = lambda net, images: inference_resnext_v1(net, images, nlayer)\n",
        "        FLAGS.learning_rate = 0.1\n",
        "    elif model_name == 'inception4':\n",
        "        height, width = 299, 299\n",
        "        model_func = inference_inception_v4\n",
        "        FLAGS.learning_rate = 0.045\n",
        "    elif model_name == 'inception-resnet2':\n",
        "        height, width = 299, 299\n",
        "        model_func = inference_inception_resnet_v2\n",
        "        FLAGS.learning_rate = 0.045\n",
        "    else:\n",
        "        logger.error(\"Invalid model type: {}\".format(model_name))\n",
        "        raise ValueError(\"Invalid model type: %s\" % model_name)\n",
        "\n",
        "    if FLAGS.data_dir is None:\n",
        "        preprocessor = DummyPreprocessor(height, width, batch_size, nclass)\n",
        "    else:\n",
        "        preprocessor = ImagePreprocessor(height, width, subset)\n",
        "\n",
        "    def loss_func(images, labels, var_scope):\n",
        "        # Build the forward model\n",
        "        net = GPUNetworkBuilder(True, dtype=model_dtype)\n",
        "        output = model_func(net, images)\n",
        "        # Add final FC layer to produce nclass outputs\n",
        "        logits = net.fully_connected(output, nclass, activation='LINEAR')\n",
        "        if logits.dtype != tf.float32:\n",
        "            logits = tf.cast(logits, tf.float32)\n",
        "        loss = tf.losses.sparse_softmax_cross_entropy(\n",
        "            logits=logits, labels=labels)\n",
        "        # Add weight decay\n",
        "        if FLAGS.weight_decay is not None and FLAGS.weight_decay != 0.:\n",
        "            params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
        "                                       scope=var_scope.name)\n",
        "            l2_loss = tf.add_n([tf.nn.l2_loss(w) for w in params])\n",
        "            if l2_loss.dtype != tf.float32:\n",
        "                l2_loss = tf.cast(l2_loss, tf.float32)\n",
        "            loss += FLAGS.weight_decay * l2_loss\n",
        "        return loss, logits\n",
        "    def eval_func(images, labels, var_scope):\n",
        "        net = GPUNetworkBuilder(False, dtype=model_dtype)\n",
        "        output = model_func(net, images)\n",
        "        logits = net.fully_connected(output, nclass, activation='LINEAR')\n",
        "        if logits.dtype != tf.float32:\n",
        "            logits = tf.cast(logits, tf.float32)\n",
        "        with tf.device('/cpu:0'):\n",
        "            top1 = tf.reduce_mean(\n",
        "                tf.cast(tf.nn.in_top_k(logits, labels, 1), tf.float32))\n",
        "            top5 = tf.reduce_mean(\n",
        "                tf.cast(tf.nn.in_top_k(logits, labels, 5), tf.float32))\n",
        "        return top1, top5\n",
        "\n",
        "    if FLAGS.eval:\n",
        "        if FLAGS.data_dir is None:\n",
        "            logger.error(\"eval requires data_dir to be specified\")\n",
        "            raise ValueError(\"eval requires data_dir to be specified\")\n",
        "        if FLAGS.fp16:\n",
        "            logger.error(\"eval cannot be run with in fp16\")\n",
        "            raise ValueError(\"eval cannot be run with in fp16\")\n",
        "        if hvd.size() > 1:\n",
        "            logger.error(\"Multi-GPU evaluation is not supported\")\n",
        "            raise ValueError(\"Multi-GPU evaluation is not supported\")\n",
        "        evaluator = FeedForwardEvaluator(preprocessor, eval_func)\n",
        "        logger.info(\"Building evaluation graph\")\n",
        "        top1_op, top5_op, enqueue_ops = evaluator.evaluation_step(batch_size)\n",
        "    else:\n",
        "        nstep_per_epoch = nrecord // (batch_size * hvd.size())\n",
        "        trainer = FeedForwardTrainer(preprocessor, loss_func, nstep_per_epoch)\n",
        "        logger.info(\"Building training graph\")\n",
        "        total_loss, learning_rate, train_ops = trainer.training_step(\n",
        "            batch_size)\n",
        "\n",
        "    logger.info(\"Creating session\")\n",
        "    config = tf.ConfigProto(allow_soft_placement = True)\n",
        "    config.intra_op_parallelism_threads = 1\n",
        "    config.inter_op_parallelism_threads = 10\n",
        "    config.gpu_options.force_gpu_compatible = True\n",
        "    config.gpu_options.visible_device_list = str(hvd.local_rank())\n",
        "\n",
        "    sess = tf.Session(config=config)\n",
        "\n",
        "    train_writer = None\n",
        "    saver = None\n",
        "    summary_ops = None\n",
        "    if hvd.rank() == 0 and len(FLAGS.log_dir):\n",
        "        log_dir = FLAGS.log_dir\n",
        "        train_writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
        "        summary_ops = tf.summary.merge_all()\n",
        "        last_summary_time = time.time()\n",
        "        saver = tf.train.Saver(keep_checkpoint_every_n_hours=3)\n",
        "        last_save_time = time.time()\n",
        "\n",
        "    if not FLAGS.eval:\n",
        "        logger.info(\"Initializing variables\")\n",
        "        trainer.init(sess)\n",
        "\n",
        "    restored = False\n",
        "    if hvd.rank() == 0 and saver is not None:\n",
        "#        ckpt = tf.train.get_checkpoint_state(FLAGS.log_dir)\n",
        "#        checkpoint_file = os.path.join(FLAGS.log_dir, \"checkpoint\")\n",
        "#        if ckpt and ckpt.model_checkpoint_path:\n",
        "#            saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "#            restored = True\n",
        "#            logger.info(\"Restored session from checkpoint {}\".format(ckpt.model_checkpoint_path))\n",
        "#        else:\n",
        "#            if not os.path.exists(FLAGS.log_dir):\n",
        "#                os.mkdir(FLAGS.log_dir)\n",
        "#\n",
        "#    if FLAGS.eval:\n",
        "#        if not restored:\n",
        "#            logger.error(\"No checkpoint found for evaluation\")\n",
        "#            raise ValueError(\"No checkpoint found for evaluation\")\n",
        "#        else:\n",
        "\n",
        "#        print(tf.train.get_checkpoint_state(FLAGS.log_dir).all_model_checkpoint_paths)\n",
        "\n",
        "        ckpts = set()\n",
        "        for item in os.listdir(FLAGS.log_dir):\n",
        "          if item.startswith('checkpoint'):\n",
        "            comps = item.split('.')\n",
        "            if len(comps) == 1:\n",
        "              continue\n",
        "            ckpt = comps[0]\n",
        "            ckpts.add(os.path.join(FLAGS.log_dir, ckpt))\n",
        "        ckpts = list(ckpts)\n",
        "        ckpts.sort()\n",
        "\n",
        "        for ckpt in ckpts:\n",
        "            saver.restore(sess, ckpt)\n",
        "            logger.info(\"Pre-filling input pipeline\")\n",
        "            evaluator.prefill_pipeline(sess)\n",
        "            nstep = nrecord // batch_size\n",
        "            ckpt_step = int(ckpt.split('-')[-1])\n",
        "\n",
        "            #if ckpt_step < 56000:\n",
        "            #  continue\n",
        "\n",
        "            run_evaluation(nstep, sess, top1_op, top5_op, enqueue_ops, ckpt.split('-')[-1])\n",
        "\n",
        "        return\n",
        "\n",
        "    trainer.sync(sess)\n",
        "\n",
        "    if hvd.rank() == 0 and not restored:\n",
        "        if saver is not None:\n",
        "            save_path = saver.save(sess, checkpoint_file, global_step=0)\n",
        "            print(\"Checkpoint written to\", save_path)\n",
        "\n",
        "    logger.info(\"Pre-filling input pipeline\")\n",
        "    trainer.prefill_pipeline(sess)\n",
        "    logger.info(\"Writing summaries to {}\".format(FLAGS.log_dir))\n",
        "    logger.info(\"Training\")\n",
        "    logger.info(\"  Step Epoch Img/sec   Loss   LR\")\n",
        "    batch_times = []\n",
        "    oom = False\n",
        "    step0 = int(sess.run(trainer.global_step))\n",
        "\n",
        "    all_stats = []\n",
        "\n",
        "    for step in range(step0, nstep):\n",
        "        ops_to_run = [total_loss, learning_rate] + train_ops\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            run_options = tf.RunOptions(trace_level=tf.RunOptions.SOFTWARE_TRACE)\n",
        "            run_metadata = tf.RunMetadata()\n",
        "            if (hvd.rank() == 0 and summary_ops is not None and\n",
        "                (step == 0 or step+1 == nstep or\n",
        "                 time.time() - last_summary_time > FLAGS.summary_interval)):\n",
        "                if step != 0:\n",
        "                    last_summary_time += FLAGS.summary_interval\n",
        "                summary, loss, lr = sess.run([summary_ops] + ops_to_run, options=run_options, run_metadata=run_metadata)[:3]\n",
        "                train_writer.add_summary(summary, step)\n",
        "            else:\n",
        "                loss, lr = sess.run(ops_to_run, options=run_options, run_metadata=run_metadata)[:2]\n",
        "            elapsed = time.time() - start_time\n",
        "            all_stats.append(run_metadata.step_stats)\n",
        "        except KeyboardInterrupt:\n",
        "            logger.info(\"Keyboard interrupt\")\n",
        "            break\n",
        "        except tf.errors.ResourceExhaustedError:\n",
        "            elapsed = -1.\n",
        "            loss    = 0.\n",
        "            lr      = -1\n",
        "            oom = True\n",
        "\n",
        "        if (hvd.rank() == 0 and saver is not None and\n",
        "            (time.time() - last_save_time > FLAGS.save_interval or step+1 == nstep)):\n",
        "            last_save_time += FLAGS.save_interval\n",
        "            save_path = saver.save(sess, checkpoint_file,\n",
        "                                   global_step=trainer.global_step)\n",
        "            print(\"Checkpoint written to\", save_path)\n",
        "\n",
        "        if step >= FLAGS.nstep_burnin:\n",
        "            batch_times.append(elapsed)\n",
        "        img_per_sec = batch_size / elapsed\n",
        "        effective_accuracy = 100. / math.exp(min(loss,20.))\n",
        "        if step == 0 or (step+1) % FLAGS.display_every == 0:\n",
        "            epoch = step*batch_size*hvd.size() // nrecord\n",
        "            logger.info(\"%6i %5i %7.1f %7.3f %7.5f\" % (\n",
        "                step+1, epoch+1, img_per_sec*hvd.size(), loss, lr))\n",
        "        if oom:\n",
        "            break\n",
        "\n",
        "        if step == 30 and hvd.rank() == 1:\n",
        "            # dump the stats\n",
        "            filename = 'stats_mpi'+str(hvd.size())+'_p'+ str(hvd.rank())+ '.pkl'\n",
        "            with open(filename, 'wb') as f:\n",
        "                pickle.dump(all_stats, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    nstep = len(batch_times)\n",
        "    if nstep > 0:\n",
        "        batch_times = np.array(batch_times)\n",
        "        speeds = batch_size*hvd.size() / batch_times\n",
        "        speed_mean = np.mean(speeds)\n",
        "        if nstep > 2:\n",
        "            speed_uncertainty = np.std(speeds, ddof=1) / np.sqrt(float(nstep))\n",
        "        else:\n",
        "            speed_uncertainty = float('nan')\n",
        "        speed_madstd = 1.4826*np.median(np.abs(speeds - np.median(speeds)))\n",
        "        speed_jitter = speed_madstd\n",
        "        logger.info('-' * 64)\n",
        "        logger.info('Images/sec: %.1f +/- %.1f (jitter = %.1f)' % (\n",
        "            speed_mean, speed_uncertainty, speed_jitter))\n",
        "        logger.info('-' * 64)\n",
        "    else:\n",
        "        logger.info(\"No results, did not get past burn-in phase (%i steps)\" %\n",
        "              FLAGS.nstep_burnin)\n",
        "\n",
        "    if train_writer is not None:\n",
        "        train_writer.close()\n",
        "\n",
        "    global_end_time = time.time()\n",
        "    #logger.info(\"start time is {}, end time is {}\".format(global_start_time, global_end_time))\n",
        "    logger.info('Time used in total: %.1f seconds' % (global_end_time - global_start_time))\n",
        "\n",
        "    if oom:\n",
        "        print(\"Out of memory error detected, exiting\")\n",
        "        sys.exit(-2)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ]
}